{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Fix randomness and hide warnings\nseed = 73\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONHASHSEED'] = str(seed)\nos.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\n\nimport numpy as np\nnp.random.seed(seed)\n\nimport logging\n\nimport random\nrandom.seed(seed)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-10T09:46:27.162188Z","iopub.execute_input":"2023-11-10T09:46:27.162602Z","iopub.status.idle":"2023-11-10T09:46:27.169238Z","shell.execute_reply.started":"2023-11-10T09:46:27.162561Z","shell.execute_reply":"2023-11-10T09:46:27.168130Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Import tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\n# tf.autograph.set_verbosity(0)\ntf.get_logger().setLevel(logging.ERROR)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-11-10T09:47:09.002602Z","iopub.execute_input":"2023-11-10T09:47:09.003067Z","iopub.status.idle":"2023-11-10T09:47:24.329205Z","shell.execute_reply.started":"2023-11-10T09:47:09.003023Z","shell.execute_reply":"2023-11-10T09:47:24.328284Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"2.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import other libraries\nimport cv2\nfrom tensorflow.keras.applications.efficientnet_v2 import preprocess_input\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-11-10T09:47:24.330880Z","iopub.execute_input":"2023-11-10T09:47:24.331469Z","iopub.status.idle":"2023-11-10T09:47:25.258072Z","shell.execute_reply.started":"2023-11-10T09:47:24.331440Z","shell.execute_reply":"2023-11-10T09:47:25.257066Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#load data\ndata = np.load('/kaggle/input/clean-dataset/clean_dataset.npz', allow_pickle=True)\n\n\nX = data[\"data\"]\nY = data[\"labels\"]\nX.shape, Y.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:56:57.149008Z","iopub.execute_input":"2023-11-10T10:56:57.150050Z","iopub.status.idle":"2023-11-10T10:57:03.204534Z","shell.execute_reply.started":"2023-11-10T10:56:57.150008Z","shell.execute_reply":"2023-11-10T10:57:03.203343Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"((5004, 96, 96, 3), (5004,))"},"metadata":{}}]},{"cell_type":"code","source":"X = (X/255).astype(np.float32)\n\n#change labels in 0 for healthy and 1 for unhealthy\n\nfor i in range(Y.size):\n  if Y[i] == \"healthy\":\n    Y[i] = 0\n  else:\n    Y[i] = 1\n\nY","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:57:03.206524Z","iopub.execute_input":"2023-11-10T10:57:03.207364Z","iopub.status.idle":"2023-11-10T10:57:04.371741Z","shell.execute_reply.started":"2023-11-10T10:57:03.207327Z","shell.execute_reply":"2023-11-10T10:57:04.370687Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, ..., 0, 0, 0], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"idx = np.random.permutation(len(Y))\nX,Y = X[idx], Y[idx]","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:57:04.946574Z","iopub.execute_input":"2023-11-10T10:57:04.947738Z","iopub.status.idle":"2023-11-10T10:57:05.137813Z","shell.execute_reply.started":"2023-11-10T10:57:04.947695Z","shell.execute_reply":"2023-11-10T10:57:05.137011Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#train, validation, test split (80,10,10)\n\n#one-hot encoding\ny = tfk.utils.to_categorical(Y,2)\n\n# Split data into train_val and test sets\nX_train_val, X_test, y_train_val, y_test = train_test_split(X, y, random_state=seed, test_size=520, stratify=np.argmax(y,axis=1))\n\n# Further split train_val into train and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=seed, test_size=520, stratify=np.argmax(y_train_val,axis=1))\n\n# Print shapes of the datasets\nprint(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\nprint(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\nprint(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-10T09:47:54.410635Z","iopub.execute_input":"2023-11-10T09:47:54.411531Z","iopub.status.idle":"2023-11-10T09:47:54.731097Z","shell.execute_reply.started":"2023-11-10T09:47:54.411485Z","shell.execute_reply":"2023-11-10T09:47:54.729935Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"X_train shape: (3964, 96, 96, 3), y_train shape: (3964, 2)\nX_val shape: (520, 96, 96, 3), y_val shape: (520, 2)\nX_test shape: (520, 96, 96, 3), y_test shape: (520, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetV2M\nmodel = EfficientNetV2M(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=(96,96,3),\n    pooling='avg',\n)\n\nmodel.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:23:06.877946Z","iopub.execute_input":"2023-11-10T10:23:06.878734Z","iopub.status.idle":"2023-11-10T10:23:13.282203Z","shell.execute_reply.started":"2023-11-10T10:23:06.878698Z","shell.execute_reply":"2023-11-10T10:23:13.281183Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Model with data augmentation","metadata":{}},{"cell_type":"code","source":"# Use the supernet as feature extractor, i.e. freeze all its weigths\nmodel.trainable = False\n\n# Create an input layer with shape (96, 96, 3)\ninputs = tfk.Input(shape=(96, 96, 3))\n\npreprocessing = tf.keras.Sequential([\n    tfkl.RandomTranslation(height_factor=(-0.2, 0.3), width_factor=(-0.2, 0.3)),\n    tfkl.RandomFlip(mode=\"horizontal_and_vertical\", seed=None),\n], name='preprocessing')\n\npreprocessing = preprocessing(inputs)\n\n\n# Connect EfficientNet to the input\nx = model(preprocessing)\n\n# Add a Dense layer with 2 units and softmax activation as the classifier\noutputs = tfkl.Dense(2, activation='softmax')(x)\n\n# Create a Model connecting input and output\ntl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n\n# Define optimizer, loss, and metrics\n# AdamW is an Adam optimizer which applies weight_decay to network layers,\n# i.e it's another way to apply l2 regularization to the whole network\noptimizer = tfk.optimizers.AdamW(1e-4, weight_decay=5e-4)\nloss = tfk.losses.CategoricalCrossentropy()\nmetrics = ['accuracy']\n\n# Compile the model with Categorical Cross-Entropy loss and Adam optimizer\ntl_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n\n# Display model summary\ntl_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T16:03:47.883616Z","iopub.execute_input":"2023-11-09T16:03:47.884369Z","iopub.status.idle":"2023-11-09T16:03:50.582626Z","shell.execute_reply.started":"2023-11-09T16:03:47.884331Z","shell.execute_reply":"2023-11-09T16:03:50.581656Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_2 (InputLayer)        [(None, 96, 96, 3)]       0         \n                                                                 \n preprocessing (Sequential)  (None, 96, 96, 3)         0         \n                                                                 \n efficientnetv2-m (Functiona  (None, 1280)             53150388  \n l)                                                              \n                                                                 \n dense (Dense)               (None, 2)                 2562      \n                                                                 \n=================================================================\nTotal params: 53,152,950\nTrainable params: 2,562\nNon-trainable params: 53,150,388\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model without data augmentation","metadata":{}},{"cell_type":"code","source":"# Use the supernet as feature extractor, i.e. freeze all its weigths\nmodel.trainable = False\n\n# Create an input layer with shape (96, 96, 3)\ninputs = tfk.Input(shape=(96, 96, 3))\n\n\n# Connect EfficientNet to the input\nx = model(inputs)\n\n# Add a Dense layer with 2 units and softmax activation as the classifier\noutputs = tfkl.Dense(2, activation='softmax')(x)\n\n# Create a Model connecting input and output\ntl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n\n# Define optimizer, loss, and metrics\n# AdamW is an Adam optimizer which applies weight_decay to network layers,\n# i.e it's another way to apply l2 regularization to the whole network\noptimizer = tfk.optimizers.AdamW(1e-4, weight_decay=5e-4)\nloss = tfk.losses.CategoricalCrossentropy()\nmetrics = ['accuracy']\n\n# Compile the model with Categorical Cross-Entropy loss and Adam optimizer\ntl_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n\n# Display model summary\ntl_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model with added dense + batch norm + dropout + augmentation","metadata":{}},{"cell_type":"code","source":"# Use the supernet as feature extractor, i.e. freeze all its weigths\nmodel.trainable = False\n\n# Create an input layer with shape (96, 96, 3)\ninputs = tfk.Input(shape=(96, 96, 3))\n\npreprocessing = tf.keras.Sequential([\n    tfkl.RandomTranslation(height_factor=(-0.2, 0.3), width_factor=(-0.2, 0.3)),\n    tfkl.RandomFlip(mode=\"horizontal_and_vertical\", seed=None),\n], name='preprocessing')\n\npreprocessing = preprocessing(inputs)\n\n\n# Connect EfficientNet to the input\nx = model(preprocessing)\n\nx = tfkl.Dense(64, activation='swish')(x)\n\nx = tfkl.BatchNormalization(name='BatchNorm0')(x)\n\n# Add a Dense layer with 2 units and softmax activation as the classifier\noutputs = tfkl.Dense(2, activation='softmax')(x)\n\n# Create a Model connecting input and output\ntl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n\n# Define optimizer, loss, and metrics\n# AdamW is an Adam optimizer which applies weight_decay to network layers,\n# i.e it's another way to apply l2 regularization to the whole network\noptimizer = tfk.optimizers.AdamW(1e-4, weight_decay=5e-4)\nloss = tfk.losses.CategoricalCrossentropy()\nmetrics = ['accuracy']\n\n# Compile the model with Categorical Cross-Entropy loss and Adam optimizer\ntl_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n\n# Display model summary\ntl_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T16:40:21.737468Z","iopub.execute_input":"2023-11-09T16:40:21.737927Z","iopub.status.idle":"2023-11-09T16:40:24.829284Z","shell.execute_reply.started":"2023-11-09T16:40:21.737890Z","shell.execute_reply":"2023-11-09T16:40:24.828380Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_4 (InputLayer)        [(None, 96, 96, 3)]       0         \n                                                                 \n preprocessing (Sequential)  (None, 96, 96, 3)         0         \n                                                                 \n efficientnetv2-m (Functiona  (None, 1280)             53150388  \n l)                                                              \n                                                                 \n dense_3 (Dense)             (None, 64)                81984     \n                                                                 \n BatchNorm0 (BatchNormalizat  (None, 64)               256       \n ion)                                                            \n                                                                 \n dense_4 (Dense)             (None, 2)                 130       \n                                                                 \n=================================================================\nTotal params: 53,232,758\nTrainable params: 82,242\nNon-trainable params: 53,150,516\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Building the model with hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"def build_model(hp):\n    output_dense_layer_units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n    dropout = hp.Boolean(\"dropout\")\n    dropout_rate = hp.Float(\"droprate\", min_value=0.2, max_value=0.3, sampling=\"linear\")\n    \n    # Create an input layer with shape (96, 96, 3)\n    inputs = tfk.Input(shape=(96, 96, 3))\n\n    preprocessing = tf.keras.Sequential([\n        tfkl.RandomTranslation(height_factor=(-0.2, 0.3), width_factor=(-0.2, 0.3)),\n        tfkl.RandomFlip(mode=\"horizontal_and_vertical\", seed=None),\n    ], name='preprocessing')\n\n    preprocessing = preprocessing(inputs)\n\n\n    # Connect EfficientNet to the input\n    x = model(preprocessing)\n\n    x = tfkl.Dense(units = output_dense_layer_units, activation='swish')(x)\n    \n    if dropout:\n        x = tfkl.Dropout(rate=dropout_rate)(x)\n    \n    x = tfkl.BatchNormalization(name='BatchNorm0')(x)\n    \n    \n    \n    # Add a Dense layer with 2 units and softmax activation as the classifier\n    outputs = tfkl.Dense(2, activation='softmax')(x)\n\n    # Create a Model connecting input and output\n    tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n\n    # Define optimizer, loss, and metrics\n    # AdamW is an Adam optimizer which applies weight_decay to network layers,\n    # i.e it's another way to apply l2 regularization to the whole network\n    optimizer = tfk.optimizers.AdamW(1e-4, weight_decay=5e-4)\n    loss = tfk.losses.CategoricalCrossentropy()\n    metrics = ['accuracy']\n\n    # Compile the model with Categorical Cross-Entropy loss and Adam optimizer\n    tl_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n    \n    return tl_model","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:23:21.614845Z","iopub.execute_input":"2023-11-10T10:23:21.615261Z","iopub.status.idle":"2023-11-10T10:23:21.625988Z","shell.execute_reply.started":"2023-11-10T10:23:21.615230Z","shell.execute_reply":"2023-11-10T10:23:21.624864Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import keras_tuner\nbuild_model(keras_tuner.HyperParameters())","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:23:23.511482Z","iopub.execute_input":"2023-11-10T10:23:23.512203Z","iopub.status.idle":"2023-11-10T10:23:26.165792Z","shell.execute_reply.started":"2023-11-10T10:23:23.512172Z","shell.execute_reply":"2023-11-10T10:23:26.164753Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<keras.engine.functional.Functional at 0x7a2114cc9c60>"},"metadata":{}}]},{"cell_type":"code","source":"#Define the tuner\ntuner = keras_tuner.RandomSearch(\n    hypermodel=build_model,\n    objective=\"val_accuracy\",\n    max_trials=10,\n    executions_per_trial=1,\n    overwrite=True,\n    directory=\"my_dir\",\n    project_name=\"helloworld\",\n)\ntuner.search_space_summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:23:26.167605Z","iopub.execute_input":"2023-11-10T10:23:26.168359Z","iopub.status.idle":"2023-11-10T10:23:29.219704Z","shell.execute_reply.started":"2023-11-10T10:23:26.168321Z","shell.execute_reply":"2023-11-10T10:23:29.218726Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Search space summary\nDefault search space size: 3\nunits (Int)\n{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\ndropout (Boolean)\n{'default': False, 'conditions': []}\ndroprate (Float)\n{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.3, 'step': None, 'sampling': 'linear'}\n","output_type":"stream"}]},{"cell_type":"code","source":"#Start the search\ntuner.search(X_train*255, y_train, epochs=10, validation_data=(X_val*255, y_val))","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:23:29.487826Z","iopub.execute_input":"2023-11-10T10:23:29.488603Z","iopub.status.idle":"2023-11-10T10:40:54.208555Z","shell.execute_reply.started":"2023-11-10T10:23:29.488573Z","shell.execute_reply":"2023-11-10T10:40:54.206967Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Trial 9 Complete [00h 01m 44s]\nval_accuracy: 0.8057692050933838\n\nBest val_accuracy So Far: 0.8153846263885498\nTotal elapsed time: 00h 15m 58s\n\nSearch: Running Trial #10\n\nValue             |Best Value So Far |Hyperparameter\n256               |224               |units\nTrue              |False             |dropout\n0.29004           |0.24571           |droprate\n\nEpoch 1/10\n124/124 [==============================] - 35s 107ms/step - loss: 0.7459 - accuracy: 0.6256 - val_loss: 0.6052 - val_accuracy: 0.7423\nEpoch 2/10\n124/124 [==============================] - 7s 54ms/step - loss: 0.6401 - accuracy: 0.6804 - val_loss: 0.5409 - val_accuracy: 0.7192\nEpoch 3/10\n124/124 [==============================] - 8s 67ms/step - loss: 0.6106 - accuracy: 0.7018 - val_loss: 0.4870 - val_accuracy: 0.7712\nEpoch 4/10\n124/124 [==============================] - 8s 67ms/step - loss: 0.5810 - accuracy: 0.7210 - val_loss: 0.4674 - val_accuracy: 0.7750\nEpoch 5/10\n124/124 [==============================] - 8s 67ms/step - loss: 0.5517 - accuracy: 0.7386 - val_loss: 0.4590 - val_accuracy: 0.7788\nEpoch 6/10\n124/124 [==============================] - 8s 67ms/step - loss: 0.5629 - accuracy: 0.7255 - val_loss: 0.4580 - val_accuracy: 0.7827\nEpoch 7/10\n117/124 [===========================>..] - ETA: 0s - loss: 0.5735 - accuracy: 0.7254","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Start the search\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 235\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    238\u001b[0m     ):\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    243\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    251\u001b[0m         )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    286\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 287\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:214\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    213\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 214\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m tuner_utils\u001b[38;5;241m.\u001b[39mvalidate_trial_results(\n\u001b[1;32m    216\u001b[0m     results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperModel.fit()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py:144\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Get the top 2 models.\nmodels = tuner.get_best_models(num_models=2)\ntl_model= models[0] # Build the model.\n# Needed for `Sequential` without specified `input_shape`.\ntl_model.build(input_shape=(96,96,3))\ntl_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:19:45.944049Z","iopub.execute_input":"2023-11-10T10:19:45.944963Z","iopub.status.idle":"2023-11-10T10:20:22.139221Z","shell.execute_reply.started":"2023-11-10T10:19:45.944932Z","shell.execute_reply":"2023-11-10T10:20:22.138307Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 96, 96, 3)]       0         \n                                                                 \n preprocessing (Sequential)  (None, 96, 96, 3)         0         \n                                                                 \n efficientnetv2-m (Functiona  (None, 1280)             53150388  \n l)                                                              \n                                                                 \n dense (Dense)               (None, 256)               327936    \n                                                                 \n dropout (Dropout)           (None, 256)               0         \n                                                                 \n BatchNorm0 (BatchNormalizat  (None, 256)              1024      \n ion)                                                            \n                                                                 \n dense_1 (Dense)             (None, 2)                 514       \n                                                                 \n=================================================================\nTotal params: 53,479,862\nTrainable params: 53,187,318\nNon-trainable params: 292,544\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model\ntl_history = tl_model.fit(\n    x = preprocess_input(X_train*255), # We need to apply the preprocessing thought for the MobileNetV2 network\n    y = y_train,\n    batch_size = 64,\n    epochs = 200,\n    validation_data = (preprocess_input(X_val*255), y_val), # We need to apply the preprocessing thought for the EfficientNetV2 network\n    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True),\n                tfk.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=20, min_lr=1e-5, mode='max')]\n).history","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:21:08.184726Z","iopub.execute_input":"2023-11-10T10:21:08.185108Z","iopub.status.idle":"2023-11-10T10:22:15.623260Z","shell.execute_reply.started":"2023-11-10T10:21:08.185078Z","shell.execute_reply":"2023-11-10T10:22:15.621278Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/200\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tl_history \u001b[38;5;241m=\u001b[39m \u001b[43mtl_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# We need to apply the preprocessing thought for the MobileNetV2 network\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# We need to apply the preprocessing thought for the EfficientNetV2 network\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtfk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtfk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhistory\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:959\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    962\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn\u001b[38;5;241m.\u001b[39m_function_spec  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    963\u001b[0m       \u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m    964\u001b[0m           args, kwds))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:142\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m--> 142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    664\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    665\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 667\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1189\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n","File \u001b[0;32m/tmp/__autograph_generated_filej71kpadd.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1268\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1264\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1265\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m     )\n\u001b[1;32m   1267\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1268\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1269\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1270\u001b[0m     outputs,\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1272\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1273\u001b[0m )\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1312\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1315\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1316\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:2895\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2894\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 2895\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3696\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   3695\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 3696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1249\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1249\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1054\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1054\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/optimizers/optimizer.py:543\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \n\u001b[1;32m    524\u001b[0m \u001b[38;5;124;03mThis method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m  None\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    542\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_gradients(loss, var_list, tape)\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/optimizers/optimizer.py:1174\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m   1173\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/optimizers/optimizer.py:648\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    646\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clip_gradients(grads)\n\u001b[1;32m    647\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deduplicate_sparse_grad(grads)\n\u001b[0;32m--> 648\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_weight_decay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[1;32m    650\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_apply_gradients(grads_and_vars)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/optimizers/optimizer.py:1193\u001b[0m, in \u001b[0;36mOptimizer._apply_weight_decay\u001b[0;34m(self, variables)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[1;32m   1189\u001b[0m         distribution\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m   1190\u001b[0m             variable, weight_decay_fn, group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m         )\n\u001b[0;32m-> 1193\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistributed_apply_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribution_strategy_context\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/optimizers/optimizer.py:1189\u001b[0m, in \u001b[0;36mOptimizer._apply_weight_decay.<locals>.distributed_apply_weight_decay\u001b[0;34m(distribution, variables, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         variable\u001b[38;5;241m.\u001b[39massign_sub(variable \u001b[38;5;241m*\u001b[39m wd \u001b[38;5;241m*\u001b[39m lr)\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:2639\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2639\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_replica_ctx_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2640\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:2518\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_fn\u001b[39m(_, \u001b[38;5;241m*\u001b[39mmerged_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerged_kwargs):\n\u001b[1;32m   2516\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(var, fn, merged_args, merged_kwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n\u001b[0;32m-> 2518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreplica_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerge_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3110\u001b[0m, in \u001b[0;36mReplicaContextBase.merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3106\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3108\u001b[0m merge_fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   3109\u001b[0m     merge_fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 3110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerge_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3117\u001b[0m, in \u001b[0;36mReplicaContextBase._merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3114\u001b[0m _push_per_thread_mode(  \u001b[38;5;66;03m# thread-local, so not needed with multiple threads\u001b[39;00m\n\u001b[1;32m   3115\u001b[0m     distribution_strategy_context\u001b[38;5;241m.\u001b[39m_CrossReplicaThreadMode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy))  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3117\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3118\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3119\u001b[0m   _pop_per_thread_mode()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:2516\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update.<locals>.merge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_fn\u001b[39m(_, \u001b[38;5;241m*\u001b[39mmerged_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerged_kwargs):\n\u001b[0;32m-> 2516\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:2637\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2634\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   2635\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   2636\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 2637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2639\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   2640\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3710\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   3708\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   3709\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 3710\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3716\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3712\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   3713\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   3714\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   3715\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 3716\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   3718\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/optimizers/optimizer.py:1186\u001b[0m, in \u001b[0;36mOptimizer._apply_weight_decay.<locals>.distributed_apply_weight_decay.<locals>.weight_decay_fn\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m   1184\u001b[0m lr \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate, variable\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   1185\u001b[0m wd \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_decay, variable\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m-> 1186\u001b[0m variable\u001b[38;5;241m.\u001b[39massign_sub(\u001b[43mvariable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py:1453\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbinary_op_wrapper\u001b[39m(x, y):\n\u001b[0;32m-> 1453\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname_scope\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m name:\n\u001b[1;32m   1454\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1455\u001b[0m       \u001b[38;5;66;03m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m       \u001b[38;5;66;03m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[1;32m   1457\u001b[0m       \u001b[38;5;66;03m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m       x, y \u001b[38;5;241m=\u001b[39m maybe_promote_tensors(x, y)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:6767\u001b[0m, in \u001b[0;36mname_scope\u001b[0;34m(name, default_name, values, skip_on_eager)\u001b[0m\n\u001b[1;32m   6763\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of collections used in the default graph.\"\"\"\u001b[39;00m\n\u001b[1;32m   6764\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m get_default_graph()\u001b[38;5;241m.\u001b[39mget_all_collection_keys()\n\u001b[0;32m-> 6767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mname_scope\u001b[39m(name, default_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, skip_on_eager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   6768\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Internal-only entry point for `name_scope*`.\u001b[39;00m\n\u001b[1;32m   6769\u001b[0m \n\u001b[1;32m   6770\u001b[0m \u001b[38;5;124;03m  Internal ops do not use the public API and instead rely on\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6790\u001b[0m \u001b[38;5;124;03m    `name_scope*` context manager.\u001b[39;00m\n\u001b[1;32m   6791\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m   6792\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Evaluate the model on the test set\ntest_accuracy = tl_model.evaluate(preprocess_input(X_test*255),y_test,verbose=0)[-1]\nprint('Test set accuracy %.4f' % test_accuracy)\nfrom sklearn.metrics import precision_score, recall_score\ny_pred = tl_model.predict(preprocess_input(X_test*255))\ny_pred = tf.argmax(y_pred, axis=-1)\ny_test_true = np.argmax(y_test, axis=-1)\n# Calculate precision and recall\nprecision = precision_score(y_test_true, y_pred)\nrecall = recall_score(y_test_true, y_pred)\n\n# Print the precision and recall\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T16:49:38.558496Z","iopub.execute_input":"2023-11-09T16:49:38.558872Z","iopub.status.idle":"2023-11-09T16:49:45.278340Z","shell.execute_reply.started":"2023-11-09T16:49:38.558841Z","shell.execute_reply":"2023-11-09T16:49:45.277447Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Test set accuracy 0.8288\n17/17 [==============================] - 5s 56ms/step\nPrecision: 0.8114285714285714\nRecall: 0.7171717171717171\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the best model\ntl_model.save('EfficientNet-AUG-FC-BATCHNORM-TL')\ndel tl_model","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:35:31.939237Z","iopub.execute_input":"2023-11-09T17:35:31.939513Z","iopub.status.idle":"2023-11-09T17:35:32.710079Z","shell.execute_reply.started":"2023-11-09T17:35:31.939486Z","shell.execute_reply":"2023-11-09T17:35:32.708706Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the best model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtl_model\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEfficientNet-AUG-FC-BATCHNORM-TL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m tl_model\n","\u001b[0;31mNameError\u001b[0m: name 'tl_model' is not defined"],"ename":"NameError","evalue":"name 'tl_model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Re-load the model after transfer learning\nft_model = tfk.models.load_model('EfficientNet-AUG-FC-BATCHNORM-TL')\nft_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:36:11.581888Z","iopub.execute_input":"2023-11-09T17:36:11.582541Z","iopub.status.idle":"2023-11-09T17:37:02.444335Z","shell.execute_reply.started":"2023-11-09T17:36:11.582510Z","shell.execute_reply":"2023-11-09T17:37:02.443419Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_4 (InputLayer)        [(None, 96, 96, 3)]       0         \n                                                                 \n preprocessing (Sequential)  (None, 96, 96, 3)         0         \n                                                                 \n efficientnetv2-m (Functiona  (None, 1280)             53150388  \n l)                                                              \n                                                                 \n dense_3 (Dense)             (None, 64)                81984     \n                                                                 \n BatchNorm0 (BatchNormalizat  (None, 64)               256       \n ion)                                                            \n                                                                 \n dense_4 (Dense)             (None, 2)                 130       \n                                                                 \n=================================================================\nTotal params: 53,232,758\nTrainable params: 82,242\nNon-trainable params: 53,150,516\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set all network layers as trainable\nft_model.get_layer('efficientnetv2-m').trainable = True","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:37:48.902477Z","iopub.execute_input":"2023-11-09T17:37:48.902872Z","iopub.status.idle":"2023-11-09T17:37:48.945305Z","shell.execute_reply.started":"2023-11-09T17:37:48.902840Z","shell.execute_reply":"2023-11-09T17:37:48.944488Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"N = 664\nfor i, layer in enumerate(ft_model.get_layer('efficientnetv2-m').layers[:N]):\n  layer.trainable=False\nfor i, layer in enumerate(ft_model.get_layer('efficientnetv2-m').layers):\n   print(i, layer.name, layer.trainable)\nft_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:38:28.175401Z","iopub.execute_input":"2023-11-09T17:38:28.175796Z","iopub.status.idle":"2023-11-09T17:38:28.311840Z","shell.execute_reply.started":"2023-11-09T17:38:28.175765Z","shell.execute_reply":"2023-11-09T17:38:28.310900Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"0 input_1 False\n1 rescaling False\n2 stem_conv False\n3 stem_bn False\n4 stem_activation False\n5 block1a_project_conv False\n6 block1a_project_bn False\n7 block1a_project_activation False\n8 block1a_add False\n9 block1b_project_conv False\n10 block1b_project_bn False\n11 block1b_project_activation False\n12 block1b_drop False\n13 block1b_add False\n14 block1c_project_conv False\n15 block1c_project_bn False\n16 block1c_project_activation False\n17 block1c_drop False\n18 block1c_add False\n19 block2a_expand_conv False\n20 block2a_expand_bn False\n21 block2a_expand_activation False\n22 block2a_project_conv False\n23 block2a_project_bn False\n24 block2b_expand_conv False\n25 block2b_expand_bn False\n26 block2b_expand_activation False\n27 block2b_project_conv False\n28 block2b_project_bn False\n29 block2b_drop False\n30 block2b_add False\n31 block2c_expand_conv False\n32 block2c_expand_bn False\n33 block2c_expand_activation False\n34 block2c_project_conv False\n35 block2c_project_bn False\n36 block2c_drop False\n37 block2c_add False\n38 block2d_expand_conv False\n39 block2d_expand_bn False\n40 block2d_expand_activation False\n41 block2d_project_conv False\n42 block2d_project_bn False\n43 block2d_drop False\n44 block2d_add False\n45 block2e_expand_conv False\n46 block2e_expand_bn False\n47 block2e_expand_activation False\n48 block2e_project_conv False\n49 block2e_project_bn False\n50 block2e_drop False\n51 block2e_add False\n52 block3a_expand_conv False\n53 block3a_expand_bn False\n54 block3a_expand_activation False\n55 block3a_project_conv False\n56 block3a_project_bn False\n57 block3b_expand_conv False\n58 block3b_expand_bn False\n59 block3b_expand_activation False\n60 block3b_project_conv False\n61 block3b_project_bn False\n62 block3b_drop False\n63 block3b_add False\n64 block3c_expand_conv False\n65 block3c_expand_bn False\n66 block3c_expand_activation False\n67 block3c_project_conv False\n68 block3c_project_bn False\n69 block3c_drop False\n70 block3c_add False\n71 block3d_expand_conv False\n72 block3d_expand_bn False\n73 block3d_expand_activation False\n74 block3d_project_conv False\n75 block3d_project_bn False\n76 block3d_drop False\n77 block3d_add False\n78 block3e_expand_conv False\n79 block3e_expand_bn False\n80 block3e_expand_activation False\n81 block3e_project_conv False\n82 block3e_project_bn False\n83 block3e_drop False\n84 block3e_add False\n85 block4a_expand_conv False\n86 block4a_expand_bn False\n87 block4a_expand_activation False\n88 block4a_dwconv2 False\n89 block4a_bn False\n90 block4a_activation False\n91 block4a_se_squeeze False\n92 block4a_se_reshape False\n93 block4a_se_reduce False\n94 block4a_se_expand False\n95 block4a_se_excite False\n96 block4a_project_conv False\n97 block4a_project_bn False\n98 block4b_expand_conv False\n99 block4b_expand_bn False\n100 block4b_expand_activation False\n101 block4b_dwconv2 False\n102 block4b_bn False\n103 block4b_activation False\n104 block4b_se_squeeze False\n105 block4b_se_reshape False\n106 block4b_se_reduce False\n107 block4b_se_expand False\n108 block4b_se_excite False\n109 block4b_project_conv False\n110 block4b_project_bn False\n111 block4b_drop False\n112 block4b_add False\n113 block4c_expand_conv False\n114 block4c_expand_bn False\n115 block4c_expand_activation False\n116 block4c_dwconv2 False\n117 block4c_bn False\n118 block4c_activation False\n119 block4c_se_squeeze False\n120 block4c_se_reshape False\n121 block4c_se_reduce False\n122 block4c_se_expand False\n123 block4c_se_excite False\n124 block4c_project_conv False\n125 block4c_project_bn False\n126 block4c_drop False\n127 block4c_add False\n128 block4d_expand_conv False\n129 block4d_expand_bn False\n130 block4d_expand_activation False\n131 block4d_dwconv2 False\n132 block4d_bn False\n133 block4d_activation False\n134 block4d_se_squeeze False\n135 block4d_se_reshape False\n136 block4d_se_reduce False\n137 block4d_se_expand False\n138 block4d_se_excite False\n139 block4d_project_conv False\n140 block4d_project_bn False\n141 block4d_drop False\n142 block4d_add False\n143 block4e_expand_conv False\n144 block4e_expand_bn False\n145 block4e_expand_activation False\n146 block4e_dwconv2 False\n147 block4e_bn False\n148 block4e_activation False\n149 block4e_se_squeeze False\n150 block4e_se_reshape False\n151 block4e_se_reduce False\n152 block4e_se_expand False\n153 block4e_se_excite False\n154 block4e_project_conv False\n155 block4e_project_bn False\n156 block4e_drop False\n157 block4e_add False\n158 block4f_expand_conv False\n159 block4f_expand_bn False\n160 block4f_expand_activation False\n161 block4f_dwconv2 False\n162 block4f_bn False\n163 block4f_activation False\n164 block4f_se_squeeze False\n165 block4f_se_reshape False\n166 block4f_se_reduce False\n167 block4f_se_expand False\n168 block4f_se_excite False\n169 block4f_project_conv False\n170 block4f_project_bn False\n171 block4f_drop False\n172 block4f_add False\n173 block4g_expand_conv False\n174 block4g_expand_bn False\n175 block4g_expand_activation False\n176 block4g_dwconv2 False\n177 block4g_bn False\n178 block4g_activation False\n179 block4g_se_squeeze False\n180 block4g_se_reshape False\n181 block4g_se_reduce False\n182 block4g_se_expand False\n183 block4g_se_excite False\n184 block4g_project_conv False\n185 block4g_project_bn False\n186 block4g_drop False\n187 block4g_add False\n188 block5a_expand_conv False\n189 block5a_expand_bn False\n190 block5a_expand_activation False\n191 block5a_dwconv2 False\n192 block5a_bn False\n193 block5a_activation False\n194 block5a_se_squeeze False\n195 block5a_se_reshape False\n196 block5a_se_reduce False\n197 block5a_se_expand False\n198 block5a_se_excite False\n199 block5a_project_conv False\n200 block5a_project_bn False\n201 block5b_expand_conv False\n202 block5b_expand_bn False\n203 block5b_expand_activation False\n204 block5b_dwconv2 False\n205 block5b_bn False\n206 block5b_activation False\n207 block5b_se_squeeze False\n208 block5b_se_reshape False\n209 block5b_se_reduce False\n210 block5b_se_expand False\n211 block5b_se_excite False\n212 block5b_project_conv False\n213 block5b_project_bn False\n214 block5b_drop False\n215 block5b_add False\n216 block5c_expand_conv False\n217 block5c_expand_bn False\n218 block5c_expand_activation False\n219 block5c_dwconv2 False\n220 block5c_bn False\n221 block5c_activation False\n222 block5c_se_squeeze False\n223 block5c_se_reshape False\n224 block5c_se_reduce False\n225 block5c_se_expand False\n226 block5c_se_excite False\n227 block5c_project_conv False\n228 block5c_project_bn False\n229 block5c_drop False\n230 block5c_add False\n231 block5d_expand_conv False\n232 block5d_expand_bn False\n233 block5d_expand_activation False\n234 block5d_dwconv2 False\n235 block5d_bn False\n236 block5d_activation False\n237 block5d_se_squeeze False\n238 block5d_se_reshape False\n239 block5d_se_reduce False\n240 block5d_se_expand False\n241 block5d_se_excite False\n242 block5d_project_conv False\n243 block5d_project_bn False\n244 block5d_drop False\n245 block5d_add False\n246 block5e_expand_conv False\n247 block5e_expand_bn False\n248 block5e_expand_activation False\n249 block5e_dwconv2 False\n250 block5e_bn False\n251 block5e_activation False\n252 block5e_se_squeeze False\n253 block5e_se_reshape False\n254 block5e_se_reduce False\n255 block5e_se_expand False\n256 block5e_se_excite False\n257 block5e_project_conv False\n258 block5e_project_bn False\n259 block5e_drop False\n260 block5e_add False\n261 block5f_expand_conv False\n262 block5f_expand_bn False\n263 block5f_expand_activation False\n264 block5f_dwconv2 False\n265 block5f_bn False\n266 block5f_activation False\n267 block5f_se_squeeze False\n268 block5f_se_reshape False\n269 block5f_se_reduce False\n270 block5f_se_expand False\n271 block5f_se_excite False\n272 block5f_project_conv False\n273 block5f_project_bn False\n274 block5f_drop False\n275 block5f_add False\n276 block5g_expand_conv False\n277 block5g_expand_bn False\n278 block5g_expand_activation False\n279 block5g_dwconv2 False\n280 block5g_bn False\n281 block5g_activation False\n282 block5g_se_squeeze False\n283 block5g_se_reshape False\n284 block5g_se_reduce False\n285 block5g_se_expand False\n286 block5g_se_excite False\n287 block5g_project_conv False\n288 block5g_project_bn False\n289 block5g_drop False\n290 block5g_add False\n291 block5h_expand_conv False\n292 block5h_expand_bn False\n293 block5h_expand_activation False\n294 block5h_dwconv2 False\n295 block5h_bn False\n296 block5h_activation False\n297 block5h_se_squeeze False\n298 block5h_se_reshape False\n299 block5h_se_reduce False\n300 block5h_se_expand False\n301 block5h_se_excite False\n302 block5h_project_conv False\n303 block5h_project_bn False\n304 block5h_drop False\n305 block5h_add False\n306 block5i_expand_conv False\n307 block5i_expand_bn False\n308 block5i_expand_activation False\n309 block5i_dwconv2 False\n310 block5i_bn False\n311 block5i_activation False\n312 block5i_se_squeeze False\n313 block5i_se_reshape False\n314 block5i_se_reduce False\n315 block5i_se_expand False\n316 block5i_se_excite False\n317 block5i_project_conv False\n318 block5i_project_bn False\n319 block5i_drop False\n320 block5i_add False\n321 block5j_expand_conv False\n322 block5j_expand_bn False\n323 block5j_expand_activation False\n324 block5j_dwconv2 False\n325 block5j_bn False\n326 block5j_activation False\n327 block5j_se_squeeze False\n328 block5j_se_reshape False\n329 block5j_se_reduce False\n330 block5j_se_expand False\n331 block5j_se_excite False\n332 block5j_project_conv False\n333 block5j_project_bn False\n334 block5j_drop False\n335 block5j_add False\n336 block5k_expand_conv False\n337 block5k_expand_bn False\n338 block5k_expand_activation False\n339 block5k_dwconv2 False\n340 block5k_bn False\n341 block5k_activation False\n342 block5k_se_squeeze False\n343 block5k_se_reshape False\n344 block5k_se_reduce False\n345 block5k_se_expand False\n346 block5k_se_excite False\n347 block5k_project_conv False\n348 block5k_project_bn False\n349 block5k_drop False\n350 block5k_add False\n351 block5l_expand_conv False\n352 block5l_expand_bn False\n353 block5l_expand_activation False\n354 block5l_dwconv2 False\n355 block5l_bn False\n356 block5l_activation False\n357 block5l_se_squeeze False\n358 block5l_se_reshape False\n359 block5l_se_reduce False\n360 block5l_se_expand False\n361 block5l_se_excite False\n362 block5l_project_conv False\n363 block5l_project_bn False\n364 block5l_drop False\n365 block5l_add False\n366 block5m_expand_conv False\n367 block5m_expand_bn False\n368 block5m_expand_activation False\n369 block5m_dwconv2 False\n370 block5m_bn False\n371 block5m_activation False\n372 block5m_se_squeeze False\n373 block5m_se_reshape False\n374 block5m_se_reduce False\n375 block5m_se_expand False\n376 block5m_se_excite False\n377 block5m_project_conv False\n378 block5m_project_bn False\n379 block5m_drop False\n380 block5m_add False\n381 block5n_expand_conv False\n382 block5n_expand_bn False\n383 block5n_expand_activation False\n384 block5n_dwconv2 False\n385 block5n_bn False\n386 block5n_activation False\n387 block5n_se_squeeze False\n388 block5n_se_reshape False\n389 block5n_se_reduce False\n390 block5n_se_expand False\n391 block5n_se_excite False\n392 block5n_project_conv False\n393 block5n_project_bn False\n394 block5n_drop False\n395 block5n_add False\n396 block6a_expand_conv False\n397 block6a_expand_bn False\n398 block6a_expand_activation False\n399 block6a_dwconv2 False\n400 block6a_bn False\n401 block6a_activation False\n402 block6a_se_squeeze False\n403 block6a_se_reshape False\n404 block6a_se_reduce False\n405 block6a_se_expand False\n406 block6a_se_excite False\n407 block6a_project_conv False\n408 block6a_project_bn False\n409 block6b_expand_conv False\n410 block6b_expand_bn False\n411 block6b_expand_activation False\n412 block6b_dwconv2 False\n413 block6b_bn False\n414 block6b_activation False\n415 block6b_se_squeeze False\n416 block6b_se_reshape False\n417 block6b_se_reduce False\n418 block6b_se_expand False\n419 block6b_se_excite False\n420 block6b_project_conv False\n421 block6b_project_bn False\n422 block6b_drop False\n423 block6b_add False\n424 block6c_expand_conv False\n425 block6c_expand_bn False\n426 block6c_expand_activation False\n427 block6c_dwconv2 False\n428 block6c_bn False\n429 block6c_activation False\n430 block6c_se_squeeze False\n431 block6c_se_reshape False\n432 block6c_se_reduce False\n433 block6c_se_expand False\n434 block6c_se_excite False\n435 block6c_project_conv False\n436 block6c_project_bn False\n437 block6c_drop False\n438 block6c_add False\n439 block6d_expand_conv False\n440 block6d_expand_bn False\n441 block6d_expand_activation False\n442 block6d_dwconv2 False\n443 block6d_bn False\n444 block6d_activation False\n445 block6d_se_squeeze False\n446 block6d_se_reshape False\n447 block6d_se_reduce False\n448 block6d_se_expand False\n449 block6d_se_excite False\n450 block6d_project_conv False\n451 block6d_project_bn False\n452 block6d_drop False\n453 block6d_add False\n454 block6e_expand_conv False\n455 block6e_expand_bn False\n456 block6e_expand_activation False\n457 block6e_dwconv2 False\n458 block6e_bn False\n459 block6e_activation False\n460 block6e_se_squeeze False\n461 block6e_se_reshape False\n462 block6e_se_reduce False\n463 block6e_se_expand False\n464 block6e_se_excite False\n465 block6e_project_conv False\n466 block6e_project_bn False\n467 block6e_drop False\n468 block6e_add False\n469 block6f_expand_conv False\n470 block6f_expand_bn False\n471 block6f_expand_activation False\n472 block6f_dwconv2 False\n473 block6f_bn False\n474 block6f_activation False\n475 block6f_se_squeeze False\n476 block6f_se_reshape False\n477 block6f_se_reduce False\n478 block6f_se_expand False\n479 block6f_se_excite False\n480 block6f_project_conv False\n481 block6f_project_bn False\n482 block6f_drop False\n483 block6f_add False\n484 block6g_expand_conv False\n485 block6g_expand_bn False\n486 block6g_expand_activation False\n487 block6g_dwconv2 False\n488 block6g_bn False\n489 block6g_activation False\n490 block6g_se_squeeze False\n491 block6g_se_reshape False\n492 block6g_se_reduce False\n493 block6g_se_expand False\n494 block6g_se_excite False\n495 block6g_project_conv False\n496 block6g_project_bn False\n497 block6g_drop False\n498 block6g_add False\n499 block6h_expand_conv False\n500 block6h_expand_bn False\n501 block6h_expand_activation False\n502 block6h_dwconv2 False\n503 block6h_bn False\n504 block6h_activation False\n505 block6h_se_squeeze False\n506 block6h_se_reshape False\n507 block6h_se_reduce False\n508 block6h_se_expand False\n509 block6h_se_excite False\n510 block6h_project_conv False\n511 block6h_project_bn False\n512 block6h_drop False\n513 block6h_add False\n514 block6i_expand_conv False\n515 block6i_expand_bn False\n516 block6i_expand_activation False\n517 block6i_dwconv2 False\n518 block6i_bn False\n519 block6i_activation False\n520 block6i_se_squeeze False\n521 block6i_se_reshape False\n522 block6i_se_reduce False\n523 block6i_se_expand False\n524 block6i_se_excite False\n525 block6i_project_conv False\n526 block6i_project_bn False\n527 block6i_drop False\n528 block6i_add False\n529 block6j_expand_conv False\n530 block6j_expand_bn False\n531 block6j_expand_activation False\n532 block6j_dwconv2 False\n533 block6j_bn False\n534 block6j_activation False\n535 block6j_se_squeeze False\n536 block6j_se_reshape False\n537 block6j_se_reduce False\n538 block6j_se_expand False\n539 block6j_se_excite False\n540 block6j_project_conv False\n541 block6j_project_bn False\n542 block6j_drop False\n543 block6j_add False\n544 block6k_expand_conv False\n545 block6k_expand_bn False\n546 block6k_expand_activation False\n547 block6k_dwconv2 False\n548 block6k_bn False\n549 block6k_activation False\n550 block6k_se_squeeze False\n551 block6k_se_reshape False\n552 block6k_se_reduce False\n553 block6k_se_expand False\n554 block6k_se_excite False\n555 block6k_project_conv False\n556 block6k_project_bn False\n557 block6k_drop False\n558 block6k_add False\n559 block6l_expand_conv False\n560 block6l_expand_bn False\n561 block6l_expand_activation False\n562 block6l_dwconv2 False\n563 block6l_bn False\n564 block6l_activation False\n565 block6l_se_squeeze False\n566 block6l_se_reshape False\n567 block6l_se_reduce False\n568 block6l_se_expand False\n569 block6l_se_excite False\n570 block6l_project_conv False\n571 block6l_project_bn False\n572 block6l_drop False\n573 block6l_add False\n574 block6m_expand_conv False\n575 block6m_expand_bn False\n576 block6m_expand_activation False\n577 block6m_dwconv2 False\n578 block6m_bn False\n579 block6m_activation False\n580 block6m_se_squeeze False\n581 block6m_se_reshape False\n582 block6m_se_reduce False\n583 block6m_se_expand False\n584 block6m_se_excite False\n585 block6m_project_conv False\n586 block6m_project_bn False\n587 block6m_drop False\n588 block6m_add False\n589 block6n_expand_conv False\n590 block6n_expand_bn False\n591 block6n_expand_activation False\n592 block6n_dwconv2 False\n593 block6n_bn False\n594 block6n_activation False\n595 block6n_se_squeeze False\n596 block6n_se_reshape False\n597 block6n_se_reduce False\n598 block6n_se_expand False\n599 block6n_se_excite False\n600 block6n_project_conv False\n601 block6n_project_bn False\n602 block6n_drop False\n603 block6n_add False\n604 block6o_expand_conv True\n605 block6o_expand_bn True\n606 block6o_expand_activation True\n607 block6o_dwconv2 True\n608 block6o_bn True\n609 block6o_activation True\n610 block6o_se_squeeze True\n611 block6o_se_reshape True\n612 block6o_se_reduce True\n613 block6o_se_expand True\n614 block6o_se_excite True\n615 block6o_project_conv True\n616 block6o_project_bn True\n617 block6o_drop True\n618 block6o_add True\n619 block6p_expand_conv True\n620 block6p_expand_bn True\n621 block6p_expand_activation True\n622 block6p_dwconv2 True\n623 block6p_bn True\n624 block6p_activation True\n625 block6p_se_squeeze True\n626 block6p_se_reshape True\n627 block6p_se_reduce True\n628 block6p_se_expand True\n629 block6p_se_excite True\n630 block6p_project_conv True\n631 block6p_project_bn True\n632 block6p_drop True\n633 block6p_add True\n634 block6q_expand_conv True\n635 block6q_expand_bn True\n636 block6q_expand_activation True\n637 block6q_dwconv2 True\n638 block6q_bn True\n639 block6q_activation True\n640 block6q_se_squeeze True\n641 block6q_se_reshape True\n642 block6q_se_reduce True\n643 block6q_se_expand True\n644 block6q_se_excite True\n645 block6q_project_conv True\n646 block6q_project_bn True\n647 block6q_drop True\n648 block6q_add True\n649 block6r_expand_conv True\n650 block6r_expand_bn True\n651 block6r_expand_activation True\n652 block6r_dwconv2 True\n653 block6r_bn True\n654 block6r_activation True\n655 block6r_se_squeeze True\n656 block6r_se_reshape True\n657 block6r_se_reduce True\n658 block6r_se_expand True\n659 block6r_se_excite True\n660 block6r_project_conv True\n661 block6r_project_bn True\n662 block6r_drop True\n663 block6r_add True\n664 block7a_expand_conv True\n665 block7a_expand_bn True\n666 block7a_expand_activation True\n667 block7a_dwconv2 True\n668 block7a_bn True\n669 block7a_activation True\n670 block7a_se_squeeze True\n671 block7a_se_reshape True\n672 block7a_se_reduce True\n673 block7a_se_expand True\n674 block7a_se_excite True\n675 block7a_project_conv True\n676 block7a_project_bn True\n677 block7b_expand_conv True\n678 block7b_expand_bn True\n679 block7b_expand_activation True\n680 block7b_dwconv2 True\n681 block7b_bn True\n682 block7b_activation True\n683 block7b_se_squeeze True\n684 block7b_se_reshape True\n685 block7b_se_reduce True\n686 block7b_se_expand True\n687 block7b_se_excite True\n688 block7b_project_conv True\n689 block7b_project_bn True\n690 block7b_drop True\n691 block7b_add True\n692 block7c_expand_conv True\n693 block7c_expand_bn True\n694 block7c_expand_activation True\n695 block7c_dwconv2 True\n696 block7c_bn True\n697 block7c_activation True\n698 block7c_se_squeeze True\n699 block7c_se_reshape True\n700 block7c_se_reduce True\n701 block7c_se_expand True\n702 block7c_se_excite True\n703 block7c_project_conv True\n704 block7c_project_bn True\n705 block7c_drop True\n706 block7c_add True\n707 block7d_expand_conv True\n708 block7d_expand_bn True\n709 block7d_expand_activation True\n710 block7d_dwconv2 True\n711 block7d_bn True\n712 block7d_activation True\n713 block7d_se_squeeze True\n714 block7d_se_reshape True\n715 block7d_se_reduce True\n716 block7d_se_expand True\n717 block7d_se_excite True\n718 block7d_project_conv True\n719 block7d_project_bn True\n720 block7d_drop True\n721 block7d_add True\n722 block7e_expand_conv True\n723 block7e_expand_bn True\n724 block7e_expand_activation True\n725 block7e_dwconv2 True\n726 block7e_bn True\n727 block7e_activation True\n728 block7e_se_squeeze True\n729 block7e_se_reshape True\n730 block7e_se_reduce True\n731 block7e_se_expand True\n732 block7e_se_excite True\n733 block7e_project_conv True\n734 block7e_project_bn True\n735 block7e_drop True\n736 block7e_add True\n737 top_conv True\n738 top_bn True\n739 top_activation True\n740 avg_pool True\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_4 (InputLayer)        [(None, 96, 96, 3)]       0         \n                                                                 \n preprocessing (Sequential)  (None, 96, 96, 3)         0         \n                                                                 \n efficientnetv2-m (Functiona  (None, 1280)             53150388  \n l)                                                              \n                                                                 \n dense_3 (Dense)             (None, 64)                81984     \n                                                                 \n BatchNorm0 (BatchNormalizat  (None, 64)               256       \n ion)                                                            \n                                                                 \n dense_4 (Dense)             (None, 2)                 130       \n                                                                 \n=================================================================\nTotal params: 53,232,758\nTrainable params: 24,087,550\nNon-trainable params: 29,145,208\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define optimizer, loss, and metrics\n# AdamW is an Adam optimizer which applies weight_decay to network layers,\n# i.e it's another way to apply l2 regularization to the whole network\noptimizer = tfk.optimizers.AdamW(1e-4, weight_decay=5e-4)\nloss = tfk.losses.CategoricalCrossentropy()\nmetrics = ['accuracy']\n\n# Compile the model with Categorical Cross-Entropy loss and Adam optimizer\nft_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n\n# Display model summary\nft_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:38:36.694864Z","iopub.execute_input":"2023-11-09T17:38:36.695778Z","iopub.status.idle":"2023-11-09T17:38:36.834998Z","shell.execute_reply.started":"2023-11-09T17:38:36.695742Z","shell.execute_reply":"2023-11-09T17:38:36.834110Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_4 (InputLayer)        [(None, 96, 96, 3)]       0         \n                                                                 \n preprocessing (Sequential)  (None, 96, 96, 3)         0         \n                                                                 \n efficientnetv2-m (Functiona  (None, 1280)             53150388  \n l)                                                              \n                                                                 \n dense_3 (Dense)             (None, 64)                81984     \n                                                                 \n BatchNorm0 (BatchNormalizat  (None, 64)               256       \n ion)                                                            \n                                                                 \n dense_4 (Dense)             (None, 2)                 130       \n                                                                 \n=================================================================\nTotal params: 53,232,758\nTrainable params: 24,087,550\nNon-trainable params: 29,145,208\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model\nft_history = ft_model.fit(\n    x = preprocess_input(X_train*255), # We need to apply the preprocessing thought for the MobileNetV2 network\n    y = y_train,\n    batch_size = 64,\n    epochs = 200,\n    validation_data = (preprocess_input(X_val*255), y_val), # We need to apply the preprocessing thought for the EfficientNetV2 network\n    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True),\n                tfk.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=20, min_lr=1e-5, mode='max')]\n).history","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:38:43.223173Z","iopub.execute_input":"2023-11-09T17:38:43.223551Z","iopub.status.idle":"2023-11-09T17:49:41.777422Z","shell.execute_reply.started":"2023-11-09T17:38:43.223521Z","shell.execute_reply":"2023-11-09T17:49:41.776499Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 1/200\n62/62 [==============================] - 73s 266ms/step - loss: 0.5927 - accuracy: 0.7422 - val_loss: 0.5623 - val_accuracy: 0.7404 - lr: 1.0000e-04\nEpoch 2/200\n62/62 [==============================] - 10s 154ms/step - loss: 0.4643 - accuracy: 0.7725 - val_loss: 0.4301 - val_accuracy: 0.8019 - lr: 1.0000e-04\nEpoch 3/200\n62/62 [==============================] - 9s 153ms/step - loss: 0.4176 - accuracy: 0.8027 - val_loss: 0.3880 - val_accuracy: 0.8212 - lr: 1.0000e-04\nEpoch 4/200\n62/62 [==============================] - 10s 154ms/step - loss: 0.4016 - accuracy: 0.8252 - val_loss: 0.3584 - val_accuracy: 0.8423 - lr: 1.0000e-04\nEpoch 5/200\n62/62 [==============================] - 10s 155ms/step - loss: 0.3635 - accuracy: 0.8421 - val_loss: 0.3462 - val_accuracy: 0.8500 - lr: 1.0000e-04\nEpoch 6/200\n62/62 [==============================] - 9s 150ms/step - loss: 0.3396 - accuracy: 0.8517 - val_loss: 0.3492 - val_accuracy: 0.8481 - lr: 1.0000e-04\nEpoch 7/200\n62/62 [==============================] - 9s 150ms/step - loss: 0.3486 - accuracy: 0.8431 - val_loss: 0.3574 - val_accuracy: 0.8500 - lr: 1.0000e-04\nEpoch 8/200\n62/62 [==============================] - 9s 149ms/step - loss: 0.3178 - accuracy: 0.8587 - val_loss: 0.3404 - val_accuracy: 0.8481 - lr: 1.0000e-04\nEpoch 9/200\n62/62 [==============================] - 10s 155ms/step - loss: 0.3101 - accuracy: 0.8650 - val_loss: 0.3300 - val_accuracy: 0.8538 - lr: 1.0000e-04\nEpoch 10/200\n62/62 [==============================] - 9s 152ms/step - loss: 0.2944 - accuracy: 0.8749 - val_loss: 0.3357 - val_accuracy: 0.8615 - lr: 1.0000e-04\nEpoch 11/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.2852 - accuracy: 0.8754 - val_loss: 0.3186 - val_accuracy: 0.8596 - lr: 1.0000e-04\nEpoch 12/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.2749 - accuracy: 0.8787 - val_loss: 0.3211 - val_accuracy: 0.8538 - lr: 1.0000e-04\nEpoch 13/200\n62/62 [==============================] - 10s 154ms/step - loss: 0.2656 - accuracy: 0.8880 - val_loss: 0.3254 - val_accuracy: 0.8731 - lr: 1.0000e-04\nEpoch 14/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.2518 - accuracy: 0.8973 - val_loss: 0.3261 - val_accuracy: 0.8673 - lr: 1.0000e-04\nEpoch 15/200\n62/62 [==============================] - 10s 155ms/step - loss: 0.2568 - accuracy: 0.8946 - val_loss: 0.3337 - val_accuracy: 0.8750 - lr: 1.0000e-04\nEpoch 16/200\n62/62 [==============================] - 10s 154ms/step - loss: 0.2496 - accuracy: 0.8943 - val_loss: 0.3347 - val_accuracy: 0.8769 - lr: 1.0000e-04\nEpoch 17/200\n62/62 [==============================] - 9s 149ms/step - loss: 0.2269 - accuracy: 0.9046 - val_loss: 0.3491 - val_accuracy: 0.8654 - lr: 1.0000e-04\nEpoch 18/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.2397 - accuracy: 0.9021 - val_loss: 0.3090 - val_accuracy: 0.8673 - lr: 1.0000e-04\nEpoch 19/200\n62/62 [==============================] - 10s 154ms/step - loss: 0.2284 - accuracy: 0.9034 - val_loss: 0.3099 - val_accuracy: 0.8808 - lr: 1.0000e-04\nEpoch 20/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.2105 - accuracy: 0.9112 - val_loss: 0.3658 - val_accuracy: 0.8577 - lr: 1.0000e-04\nEpoch 21/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.2050 - accuracy: 0.9150 - val_loss: 0.3324 - val_accuracy: 0.8673 - lr: 1.0000e-04\nEpoch 22/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.2089 - accuracy: 0.9109 - val_loss: 0.3729 - val_accuracy: 0.8615 - lr: 1.0000e-04\nEpoch 23/200\n62/62 [==============================] - 9s 154ms/step - loss: 0.1902 - accuracy: 0.9263 - val_loss: 0.3001 - val_accuracy: 0.8865 - lr: 1.0000e-04\nEpoch 24/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1870 - accuracy: 0.9226 - val_loss: 0.2953 - val_accuracy: 0.8865 - lr: 1.0000e-04\nEpoch 25/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1722 - accuracy: 0.9354 - val_loss: 0.3134 - val_accuracy: 0.8692 - lr: 1.0000e-04\nEpoch 26/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1868 - accuracy: 0.9253 - val_loss: 0.3324 - val_accuracy: 0.8673 - lr: 1.0000e-04\nEpoch 27/200\n62/62 [==============================] - 10s 154ms/step - loss: 0.1727 - accuracy: 0.9319 - val_loss: 0.3473 - val_accuracy: 0.8885 - lr: 1.0000e-04\nEpoch 28/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1717 - accuracy: 0.9304 - val_loss: 0.3578 - val_accuracy: 0.8750 - lr: 1.0000e-04\nEpoch 29/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1609 - accuracy: 0.9357 - val_loss: 0.3524 - val_accuracy: 0.8769 - lr: 1.0000e-04\nEpoch 30/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1684 - accuracy: 0.9316 - val_loss: 0.3379 - val_accuracy: 0.8788 - lr: 1.0000e-04\nEpoch 31/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1665 - accuracy: 0.9357 - val_loss: 0.3328 - val_accuracy: 0.8846 - lr: 1.0000e-04\nEpoch 32/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1563 - accuracy: 0.9384 - val_loss: 0.3662 - val_accuracy: 0.8731 - lr: 1.0000e-04\nEpoch 33/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1499 - accuracy: 0.9420 - val_loss: 0.3642 - val_accuracy: 0.8673 - lr: 1.0000e-04\nEpoch 34/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.1484 - accuracy: 0.9435 - val_loss: 0.3356 - val_accuracy: 0.8769 - lr: 1.0000e-04\nEpoch 35/200\n62/62 [==============================] - 10s 156ms/step - loss: 0.1577 - accuracy: 0.9359 - val_loss: 0.3560 - val_accuracy: 0.8788 - lr: 1.0000e-04\nEpoch 36/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.1487 - accuracy: 0.9430 - val_loss: 0.3398 - val_accuracy: 0.8808 - lr: 1.0000e-04\nEpoch 37/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.1219 - accuracy: 0.9531 - val_loss: 0.4119 - val_accuracy: 0.8712 - lr: 1.0000e-04\nEpoch 38/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.1408 - accuracy: 0.9453 - val_loss: 0.3887 - val_accuracy: 0.8750 - lr: 1.0000e-04\nEpoch 39/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1453 - accuracy: 0.9455 - val_loss: 0.3513 - val_accuracy: 0.8808 - lr: 1.0000e-04\nEpoch 40/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1318 - accuracy: 0.9468 - val_loss: 0.3802 - val_accuracy: 0.8808 - lr: 1.0000e-04\nEpoch 41/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1368 - accuracy: 0.9463 - val_loss: 0.3421 - val_accuracy: 0.8865 - lr: 1.0000e-04\nEpoch 42/200\n62/62 [==============================] - 10s 154ms/step - loss: 0.1361 - accuracy: 0.9463 - val_loss: 0.3081 - val_accuracy: 0.8942 - lr: 1.0000e-04\nEpoch 43/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1262 - accuracy: 0.9518 - val_loss: 0.3185 - val_accuracy: 0.8846 - lr: 1.0000e-04\nEpoch 44/200\n62/62 [==============================] - 10s 154ms/step - loss: 0.1158 - accuracy: 0.9521 - val_loss: 0.3359 - val_accuracy: 0.9019 - lr: 1.0000e-04\nEpoch 45/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.1028 - accuracy: 0.9622 - val_loss: 0.3359 - val_accuracy: 0.8846 - lr: 1.0000e-04\nEpoch 46/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1117 - accuracy: 0.9546 - val_loss: 0.3558 - val_accuracy: 0.8846 - lr: 1.0000e-04\nEpoch 47/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1071 - accuracy: 0.9576 - val_loss: 0.3888 - val_accuracy: 0.8885 - lr: 1.0000e-04\nEpoch 48/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1296 - accuracy: 0.9478 - val_loss: 0.3666 - val_accuracy: 0.8788 - lr: 1.0000e-04\nEpoch 49/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1163 - accuracy: 0.9528 - val_loss: 0.3726 - val_accuracy: 0.8808 - lr: 1.0000e-04\nEpoch 50/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.1162 - accuracy: 0.9556 - val_loss: 0.3290 - val_accuracy: 0.8942 - lr: 1.0000e-04\nEpoch 51/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1030 - accuracy: 0.9599 - val_loss: 0.3651 - val_accuracy: 0.8904 - lr: 1.0000e-04\nEpoch 52/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.0972 - accuracy: 0.9622 - val_loss: 0.3631 - val_accuracy: 0.8923 - lr: 1.0000e-04\nEpoch 53/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.1060 - accuracy: 0.9589 - val_loss: 0.3684 - val_accuracy: 0.8846 - lr: 1.0000e-04\nEpoch 54/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.0989 - accuracy: 0.9629 - val_loss: 0.3984 - val_accuracy: 0.8615 - lr: 1.0000e-04\nEpoch 55/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.0859 - accuracy: 0.9634 - val_loss: 0.4177 - val_accuracy: 0.8750 - lr: 1.0000e-04\nEpoch 56/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.1169 - accuracy: 0.9556 - val_loss: 0.3994 - val_accuracy: 0.8692 - lr: 1.0000e-04\nEpoch 57/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.0964 - accuracy: 0.9639 - val_loss: 0.3903 - val_accuracy: 0.8885 - lr: 1.0000e-04\nEpoch 58/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.0943 - accuracy: 0.9637 - val_loss: 0.4133 - val_accuracy: 0.8769 - lr: 1.0000e-04\nEpoch 59/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.0997 - accuracy: 0.9622 - val_loss: 0.3963 - val_accuracy: 0.8827 - lr: 1.0000e-04\nEpoch 60/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.0943 - accuracy: 0.9672 - val_loss: 0.4278 - val_accuracy: 0.8750 - lr: 1.0000e-04\nEpoch 61/200\n62/62 [==============================] - 9s 147ms/step - loss: 0.0849 - accuracy: 0.9634 - val_loss: 0.3519 - val_accuracy: 0.8885 - lr: 1.0000e-04\nEpoch 62/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.0832 - accuracy: 0.9692 - val_loss: 0.4183 - val_accuracy: 0.8827 - lr: 1.0000e-04\nEpoch 63/200\n62/62 [==============================] - 9s 148ms/step - loss: 0.0933 - accuracy: 0.9649 - val_loss: 0.4150 - val_accuracy: 0.8712 - lr: 1.0000e-04\nEpoch 64/200\n62/62 [==============================] - 10s 155ms/step - loss: 0.0920 - accuracy: 0.9634 - val_loss: 0.4059 - val_accuracy: 0.8885 - lr: 1.0000e-04\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model on the test set\ntest_accuracy = ft_model.evaluate(preprocess_input(X_test*255),y_test,verbose=0)[-1]\nprint('Test set accuracy %.4f' % test_accuracy)\n\nfrom sklearn.metrics import precision_score, recall_score\ny_pred = ft_model.predict(preprocess_input(X_test*255))\ny_pred = tf.argmax(y_pred, axis=-1)\ny_test_true = np.argmax(y_test, axis=-1)\n# Calculate precision and recall\nprecision = precision_score(y_test_true, y_pred)\nrecall = recall_score(y_test_true, y_pred)\n\n# Print the precision and recall\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:50:32.416249Z","iopub.execute_input":"2023-11-09T17:50:32.416660Z","iopub.status.idle":"2023-11-09T17:50:39.761838Z","shell.execute_reply.started":"2023-11-09T17:50:32.416627Z","shell.execute_reply":"2023-11-09T17:50:39.760941Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Test set accuracy 0.8923\n17/17 [==============================] - 5s 56ms/step\nPrecision: 0.8480392156862745\nRecall: 0.8737373737373737\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the best model\nft_model.save('EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-')","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:11:33.474778Z","iopub.execute_input":"2023-11-09T17:11:33.475865Z","iopub.status.idle":"2023-11-09T17:14:54.943135Z","shell.execute_reply.started":"2023-11-09T17:11:33.475829Z","shell.execute_reply":"2023-11-09T17:14:54.942203Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\n!zip -r EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT.zip /kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:18:34.567058Z","iopub.execute_input":"2023-11-09T17:18:34.567475Z","iopub.status.idle":"2023-11-09T17:18:56.178383Z","shell.execute_reply.started":"2023-11-09T17:18:34.567441Z","shell.execute_reply":"2023-11-09T17:18:56.177170Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-/ (stored 0%)\n  adding: kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-/keras_metadata.pb (deflated 96%)\n  adding: kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-/variables/ (stored 0%)\n  adding: kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-/variables/variables.data-00000-of-00001 (deflated 9%)\n  adding: kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-/variables/variables.index (deflated 77%)\n  adding: kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-/saved_model.pb (deflated 92%)\n  adding: kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-/assets/ (stored 0%)\n  adding: kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-/fingerprint.pb (stored 0%)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.move(\"/kaggle/input/network-on-all-data/kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-\",\"/kaggle/working/\")\n#shutil.rmtree(\"/kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-\")","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:48:59.567867Z","iopub.execute_input":"2023-11-10T10:48:59.568760Z","iopub.status.idle":"2023-11-10T10:49:04.777480Z","shell.execute_reply.started":"2023-11-10T10:48:59.568726Z","shell.execute_reply":"2023-11-10T10:49:04.775585Z"},"trusted":true},"execution_count":28,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:816\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n","\u001b[0;31mOSError\u001b[0m: [Errno 18] Invalid cross-device link: '/kaggle/input/network-on-all-data/kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-' -> '/kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/network-on-all-data/kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#shutil.rmtree(\"/kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-\")\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:834\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mPermissionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot move the non-empty directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m                               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: Lacking write permission to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m                               \u001b[38;5;241m%\u001b[39m (src, src))\n\u001b[1;32m    832\u001b[0m     copytree(src, real_dst, copy_function\u001b[38;5;241m=\u001b[39mcopy_function,\n\u001b[1;32m    833\u001b[0m              symlinks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 834\u001b[0m     \u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    836\u001b[0m     copy_function(src, real_dst)\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:725\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msamestat(orig_st, os\u001b[38;5;241m.\u001b[39mfstat(fd)):\n\u001b[0;32m--> 725\u001b[0m         \u001b[43m_rmtree_safe_fd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    727\u001b[0m             os\u001b[38;5;241m.\u001b[39mclose(fd)\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:681\u001b[0m, in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    679\u001b[0m     os\u001b[38;5;241m.\u001b[39munlink(entry\u001b[38;5;241m.\u001b[39mname, dir_fd\u001b[38;5;241m=\u001b[39mtopfd)\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m--> 681\u001b[0m     \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:679\u001b[0m, in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 679\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_fd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopfd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    681\u001b[0m         onerror(os\u001b[38;5;241m.\u001b[39munlink, fullname, sys\u001b[38;5;241m.\u001b[39mexc_info())\n","\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: 'fingerprint.pb'"],"ename":"OSError","evalue":"[Errno 30] Read-only file system: 'fingerprint.pb'","output_type":"error"}]},{"cell_type":"code","source":"# Re-load the model after transfer learning\nalldata_model = tfk.models.load_model('/kaggle/working/EFFICIENTNET-AUGGGG-FC-BATCHNORM-FT-')\nalldata_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:55:10.677457Z","iopub.execute_input":"2023-11-10T10:55:10.678545Z","iopub.status.idle":"2023-11-10T10:56:05.064236Z","shell.execute_reply.started":"2023-11-10T10:55:10.678502Z","shell.execute_reply":"2023-11-10T10:56:05.063203Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_4 (InputLayer)        [(None, 96, 96, 3)]       0         \n                                                                 \n preprocessing (Sequential)  (None, 96, 96, 3)         0         \n                                                                 \n efficientnetv2-m (Functiona  (None, 1280)             53150388  \n l)                                                              \n                                                                 \n dense_3 (Dense)             (None, 64)                81984     \n                                                                 \n BatchNorm0 (BatchNormalizat  (None, 64)               256       \n ion)                                                            \n                                                                 \n dense_4 (Dense)             (None, 2)                 130       \n                                                                 \n=================================================================\nTotal params: 53,232,758\nTrainable params: 18,437,710\nNon-trainable params: 34,795,048\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set all network layers as trainable\nalldata_model.get_layer('efficientnetv2-m').trainable = True","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:56:07.210757Z","iopub.execute_input":"2023-11-10T10:56:07.211128Z","iopub.status.idle":"2023-11-10T10:56:07.249114Z","shell.execute_reply.started":"2023-11-10T10:56:07.211098Z","shell.execute_reply":"2023-11-10T10:56:07.248161Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"N = 664\nfor i, layer in enumerate(alldata_model.get_layer('efficientnetv2-m').layers[:N]):\n  layer.trainable=False\nfor i, layer in enumerate(alldata_model.get_layer('efficientnetv2-m').layers):\n   print(i, layer.name, layer.trainable)\nalldata_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:56:08.482155Z","iopub.execute_input":"2023-11-10T10:56:08.483025Z","iopub.status.idle":"2023-11-10T10:56:08.644816Z","shell.execute_reply.started":"2023-11-10T10:56:08.482990Z","shell.execute_reply":"2023-11-10T10:56:08.643619Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"0 input_1 False\n1 rescaling False\n2 stem_conv False\n3 stem_bn False\n4 stem_activation False\n5 block1a_project_conv False\n6 block1a_project_bn False\n7 block1a_project_activation False\n8 block1a_add False\n9 block1b_project_conv False\n10 block1b_project_bn False\n11 block1b_project_activation False\n12 block1b_drop False\n13 block1b_add False\n14 block1c_project_conv False\n15 block1c_project_bn False\n16 block1c_project_activation False\n17 block1c_drop False\n18 block1c_add False\n19 block2a_expand_conv False\n20 block2a_expand_bn False\n21 block2a_expand_activation False\n22 block2a_project_conv False\n23 block2a_project_bn False\n24 block2b_expand_conv False\n25 block2b_expand_bn False\n26 block2b_expand_activation False\n27 block2b_project_conv False\n28 block2b_project_bn False\n29 block2b_drop False\n30 block2b_add False\n31 block2c_expand_conv False\n32 block2c_expand_bn False\n33 block2c_expand_activation False\n34 block2c_project_conv False\n35 block2c_project_bn False\n36 block2c_drop False\n37 block2c_add False\n38 block2d_expand_conv False\n39 block2d_expand_bn False\n40 block2d_expand_activation False\n41 block2d_project_conv False\n42 block2d_project_bn False\n43 block2d_drop False\n44 block2d_add False\n45 block2e_expand_conv False\n46 block2e_expand_bn False\n47 block2e_expand_activation False\n48 block2e_project_conv False\n49 block2e_project_bn False\n50 block2e_drop False\n51 block2e_add False\n52 block3a_expand_conv False\n53 block3a_expand_bn False\n54 block3a_expand_activation False\n55 block3a_project_conv False\n56 block3a_project_bn False\n57 block3b_expand_conv False\n58 block3b_expand_bn False\n59 block3b_expand_activation False\n60 block3b_project_conv False\n61 block3b_project_bn False\n62 block3b_drop False\n63 block3b_add False\n64 block3c_expand_conv False\n65 block3c_expand_bn False\n66 block3c_expand_activation False\n67 block3c_project_conv False\n68 block3c_project_bn False\n69 block3c_drop False\n70 block3c_add False\n71 block3d_expand_conv False\n72 block3d_expand_bn False\n73 block3d_expand_activation False\n74 block3d_project_conv False\n75 block3d_project_bn False\n76 block3d_drop False\n77 block3d_add False\n78 block3e_expand_conv False\n79 block3e_expand_bn False\n80 block3e_expand_activation False\n81 block3e_project_conv False\n82 block3e_project_bn False\n83 block3e_drop False\n84 block3e_add False\n85 block4a_expand_conv False\n86 block4a_expand_bn False\n87 block4a_expand_activation False\n88 block4a_dwconv2 False\n89 block4a_bn False\n90 block4a_activation False\n91 block4a_se_squeeze False\n92 block4a_se_reshape False\n93 block4a_se_reduce False\n94 block4a_se_expand False\n95 block4a_se_excite False\n96 block4a_project_conv False\n97 block4a_project_bn False\n98 block4b_expand_conv False\n99 block4b_expand_bn False\n100 block4b_expand_activation False\n101 block4b_dwconv2 False\n102 block4b_bn False\n103 block4b_activation False\n104 block4b_se_squeeze False\n105 block4b_se_reshape False\n106 block4b_se_reduce False\n107 block4b_se_expand False\n108 block4b_se_excite False\n109 block4b_project_conv False\n110 block4b_project_bn False\n111 block4b_drop False\n112 block4b_add False\n113 block4c_expand_conv False\n114 block4c_expand_bn False\n115 block4c_expand_activation False\n116 block4c_dwconv2 False\n117 block4c_bn False\n118 block4c_activation False\n119 block4c_se_squeeze False\n120 block4c_se_reshape False\n121 block4c_se_reduce False\n122 block4c_se_expand False\n123 block4c_se_excite False\n124 block4c_project_conv False\n125 block4c_project_bn False\n126 block4c_drop False\n127 block4c_add False\n128 block4d_expand_conv False\n129 block4d_expand_bn False\n130 block4d_expand_activation False\n131 block4d_dwconv2 False\n132 block4d_bn False\n133 block4d_activation False\n134 block4d_se_squeeze False\n135 block4d_se_reshape False\n136 block4d_se_reduce False\n137 block4d_se_expand False\n138 block4d_se_excite False\n139 block4d_project_conv False\n140 block4d_project_bn False\n141 block4d_drop False\n142 block4d_add False\n143 block4e_expand_conv False\n144 block4e_expand_bn False\n145 block4e_expand_activation False\n146 block4e_dwconv2 False\n147 block4e_bn False\n148 block4e_activation False\n149 block4e_se_squeeze False\n150 block4e_se_reshape False\n151 block4e_se_reduce False\n152 block4e_se_expand False\n153 block4e_se_excite False\n154 block4e_project_conv False\n155 block4e_project_bn False\n156 block4e_drop False\n157 block4e_add False\n158 block4f_expand_conv False\n159 block4f_expand_bn False\n160 block4f_expand_activation False\n161 block4f_dwconv2 False\n162 block4f_bn False\n163 block4f_activation False\n164 block4f_se_squeeze False\n165 block4f_se_reshape False\n166 block4f_se_reduce False\n167 block4f_se_expand False\n168 block4f_se_excite False\n169 block4f_project_conv False\n170 block4f_project_bn False\n171 block4f_drop False\n172 block4f_add False\n173 block4g_expand_conv False\n174 block4g_expand_bn False\n175 block4g_expand_activation False\n176 block4g_dwconv2 False\n177 block4g_bn False\n178 block4g_activation False\n179 block4g_se_squeeze False\n180 block4g_se_reshape False\n181 block4g_se_reduce False\n182 block4g_se_expand False\n183 block4g_se_excite False\n184 block4g_project_conv False\n185 block4g_project_bn False\n186 block4g_drop False\n187 block4g_add False\n188 block5a_expand_conv False\n189 block5a_expand_bn False\n190 block5a_expand_activation False\n191 block5a_dwconv2 False\n192 block5a_bn False\n193 block5a_activation False\n194 block5a_se_squeeze False\n195 block5a_se_reshape False\n196 block5a_se_reduce False\n197 block5a_se_expand False\n198 block5a_se_excite False\n199 block5a_project_conv False\n200 block5a_project_bn False\n201 block5b_expand_conv False\n202 block5b_expand_bn False\n203 block5b_expand_activation False\n204 block5b_dwconv2 False\n205 block5b_bn False\n206 block5b_activation False\n207 block5b_se_squeeze False\n208 block5b_se_reshape False\n209 block5b_se_reduce False\n210 block5b_se_expand False\n211 block5b_se_excite False\n212 block5b_project_conv False\n213 block5b_project_bn False\n214 block5b_drop False\n215 block5b_add False\n216 block5c_expand_conv False\n217 block5c_expand_bn False\n218 block5c_expand_activation False\n219 block5c_dwconv2 False\n220 block5c_bn False\n221 block5c_activation False\n222 block5c_se_squeeze False\n223 block5c_se_reshape False\n224 block5c_se_reduce False\n225 block5c_se_expand False\n226 block5c_se_excite False\n227 block5c_project_conv False\n228 block5c_project_bn False\n229 block5c_drop False\n230 block5c_add False\n231 block5d_expand_conv False\n232 block5d_expand_bn False\n233 block5d_expand_activation False\n234 block5d_dwconv2 False\n235 block5d_bn False\n236 block5d_activation False\n237 block5d_se_squeeze False\n238 block5d_se_reshape False\n239 block5d_se_reduce False\n240 block5d_se_expand False\n241 block5d_se_excite False\n242 block5d_project_conv False\n243 block5d_project_bn False\n244 block5d_drop False\n245 block5d_add False\n246 block5e_expand_conv False\n247 block5e_expand_bn False\n248 block5e_expand_activation False\n249 block5e_dwconv2 False\n250 block5e_bn False\n251 block5e_activation False\n252 block5e_se_squeeze False\n253 block5e_se_reshape False\n254 block5e_se_reduce False\n255 block5e_se_expand False\n256 block5e_se_excite False\n257 block5e_project_conv False\n258 block5e_project_bn False\n259 block5e_drop False\n260 block5e_add False\n261 block5f_expand_conv False\n262 block5f_expand_bn False\n263 block5f_expand_activation False\n264 block5f_dwconv2 False\n265 block5f_bn False\n266 block5f_activation False\n267 block5f_se_squeeze False\n268 block5f_se_reshape False\n269 block5f_se_reduce False\n270 block5f_se_expand False\n271 block5f_se_excite False\n272 block5f_project_conv False\n273 block5f_project_bn False\n274 block5f_drop False\n275 block5f_add False\n276 block5g_expand_conv False\n277 block5g_expand_bn False\n278 block5g_expand_activation False\n279 block5g_dwconv2 False\n280 block5g_bn False\n281 block5g_activation False\n282 block5g_se_squeeze False\n283 block5g_se_reshape False\n284 block5g_se_reduce False\n285 block5g_se_expand False\n286 block5g_se_excite False\n287 block5g_project_conv False\n288 block5g_project_bn False\n289 block5g_drop False\n290 block5g_add False\n291 block5h_expand_conv False\n292 block5h_expand_bn False\n293 block5h_expand_activation False\n294 block5h_dwconv2 False\n295 block5h_bn False\n296 block5h_activation False\n297 block5h_se_squeeze False\n298 block5h_se_reshape False\n299 block5h_se_reduce False\n300 block5h_se_expand False\n301 block5h_se_excite False\n302 block5h_project_conv False\n303 block5h_project_bn False\n304 block5h_drop False\n305 block5h_add False\n306 block5i_expand_conv False\n307 block5i_expand_bn False\n308 block5i_expand_activation False\n309 block5i_dwconv2 False\n310 block5i_bn False\n311 block5i_activation False\n312 block5i_se_squeeze False\n313 block5i_se_reshape False\n314 block5i_se_reduce False\n315 block5i_se_expand False\n316 block5i_se_excite False\n317 block5i_project_conv False\n318 block5i_project_bn False\n319 block5i_drop False\n320 block5i_add False\n321 block5j_expand_conv False\n322 block5j_expand_bn False\n323 block5j_expand_activation False\n324 block5j_dwconv2 False\n325 block5j_bn False\n326 block5j_activation False\n327 block5j_se_squeeze False\n328 block5j_se_reshape False\n329 block5j_se_reduce False\n330 block5j_se_expand False\n331 block5j_se_excite False\n332 block5j_project_conv False\n333 block5j_project_bn False\n334 block5j_drop False\n335 block5j_add False\n336 block5k_expand_conv False\n337 block5k_expand_bn False\n338 block5k_expand_activation False\n339 block5k_dwconv2 False\n340 block5k_bn False\n341 block5k_activation False\n342 block5k_se_squeeze False\n343 block5k_se_reshape False\n344 block5k_se_reduce False\n345 block5k_se_expand False\n346 block5k_se_excite False\n347 block5k_project_conv False\n348 block5k_project_bn False\n349 block5k_drop False\n350 block5k_add False\n351 block5l_expand_conv False\n352 block5l_expand_bn False\n353 block5l_expand_activation False\n354 block5l_dwconv2 False\n355 block5l_bn False\n356 block5l_activation False\n357 block5l_se_squeeze False\n358 block5l_se_reshape False\n359 block5l_se_reduce False\n360 block5l_se_expand False\n361 block5l_se_excite False\n362 block5l_project_conv False\n363 block5l_project_bn False\n364 block5l_drop False\n365 block5l_add False\n366 block5m_expand_conv False\n367 block5m_expand_bn False\n368 block5m_expand_activation False\n369 block5m_dwconv2 False\n370 block5m_bn False\n371 block5m_activation False\n372 block5m_se_squeeze False\n373 block5m_se_reshape False\n374 block5m_se_reduce False\n375 block5m_se_expand False\n376 block5m_se_excite False\n377 block5m_project_conv False\n378 block5m_project_bn False\n379 block5m_drop False\n380 block5m_add False\n381 block5n_expand_conv False\n382 block5n_expand_bn False\n383 block5n_expand_activation False\n384 block5n_dwconv2 False\n385 block5n_bn False\n386 block5n_activation False\n387 block5n_se_squeeze False\n388 block5n_se_reshape False\n389 block5n_se_reduce False\n390 block5n_se_expand False\n391 block5n_se_excite False\n392 block5n_project_conv False\n393 block5n_project_bn False\n394 block5n_drop False\n395 block5n_add False\n396 block6a_expand_conv False\n397 block6a_expand_bn False\n398 block6a_expand_activation False\n399 block6a_dwconv2 False\n400 block6a_bn False\n401 block6a_activation False\n402 block6a_se_squeeze False\n403 block6a_se_reshape False\n404 block6a_se_reduce False\n405 block6a_se_expand False\n406 block6a_se_excite False\n407 block6a_project_conv False\n408 block6a_project_bn False\n409 block6b_expand_conv False\n410 block6b_expand_bn False\n411 block6b_expand_activation False\n412 block6b_dwconv2 False\n413 block6b_bn False\n414 block6b_activation False\n415 block6b_se_squeeze False\n416 block6b_se_reshape False\n417 block6b_se_reduce False\n418 block6b_se_expand False\n419 block6b_se_excite False\n420 block6b_project_conv False\n421 block6b_project_bn False\n422 block6b_drop False\n423 block6b_add False\n424 block6c_expand_conv False\n425 block6c_expand_bn False\n426 block6c_expand_activation False\n427 block6c_dwconv2 False\n428 block6c_bn False\n429 block6c_activation False\n430 block6c_se_squeeze False\n431 block6c_se_reshape False\n432 block6c_se_reduce False\n433 block6c_se_expand False\n434 block6c_se_excite False\n435 block6c_project_conv False\n436 block6c_project_bn False\n437 block6c_drop False\n438 block6c_add False\n439 block6d_expand_conv False\n440 block6d_expand_bn False\n441 block6d_expand_activation False\n442 block6d_dwconv2 False\n443 block6d_bn False\n444 block6d_activation False\n445 block6d_se_squeeze False\n446 block6d_se_reshape False\n447 block6d_se_reduce False\n448 block6d_se_expand False\n449 block6d_se_excite False\n450 block6d_project_conv False\n451 block6d_project_bn False\n452 block6d_drop False\n453 block6d_add False\n454 block6e_expand_conv False\n455 block6e_expand_bn False\n456 block6e_expand_activation False\n457 block6e_dwconv2 False\n458 block6e_bn False\n459 block6e_activation False\n460 block6e_se_squeeze False\n461 block6e_se_reshape False\n462 block6e_se_reduce False\n463 block6e_se_expand False\n464 block6e_se_excite False\n465 block6e_project_conv False\n466 block6e_project_bn False\n467 block6e_drop False\n468 block6e_add False\n469 block6f_expand_conv False\n470 block6f_expand_bn False\n471 block6f_expand_activation False\n472 block6f_dwconv2 False\n473 block6f_bn False\n474 block6f_activation False\n475 block6f_se_squeeze False\n476 block6f_se_reshape False\n477 block6f_se_reduce False\n478 block6f_se_expand False\n479 block6f_se_excite False\n480 block6f_project_conv False\n481 block6f_project_bn False\n482 block6f_drop False\n483 block6f_add False\n484 block6g_expand_conv False\n485 block6g_expand_bn False\n486 block6g_expand_activation False\n487 block6g_dwconv2 False\n488 block6g_bn False\n489 block6g_activation False\n490 block6g_se_squeeze False\n491 block6g_se_reshape False\n492 block6g_se_reduce False\n493 block6g_se_expand False\n494 block6g_se_excite False\n495 block6g_project_conv False\n496 block6g_project_bn False\n497 block6g_drop False\n498 block6g_add False\n499 block6h_expand_conv False\n500 block6h_expand_bn False\n501 block6h_expand_activation False\n502 block6h_dwconv2 False\n503 block6h_bn False\n504 block6h_activation False\n505 block6h_se_squeeze False\n506 block6h_se_reshape False\n507 block6h_se_reduce False\n508 block6h_se_expand False\n509 block6h_se_excite False\n510 block6h_project_conv False\n511 block6h_project_bn False\n512 block6h_drop False\n513 block6h_add False\n514 block6i_expand_conv False\n515 block6i_expand_bn False\n516 block6i_expand_activation False\n517 block6i_dwconv2 False\n518 block6i_bn False\n519 block6i_activation False\n520 block6i_se_squeeze False\n521 block6i_se_reshape False\n522 block6i_se_reduce False\n523 block6i_se_expand False\n524 block6i_se_excite False\n525 block6i_project_conv False\n526 block6i_project_bn False\n527 block6i_drop False\n528 block6i_add False\n529 block6j_expand_conv False\n530 block6j_expand_bn False\n531 block6j_expand_activation False\n532 block6j_dwconv2 False\n533 block6j_bn False\n534 block6j_activation False\n535 block6j_se_squeeze False\n536 block6j_se_reshape False\n537 block6j_se_reduce False\n538 block6j_se_expand False\n539 block6j_se_excite False\n540 block6j_project_conv False\n541 block6j_project_bn False\n542 block6j_drop False\n543 block6j_add False\n544 block6k_expand_conv False\n545 block6k_expand_bn False\n546 block6k_expand_activation False\n547 block6k_dwconv2 False\n548 block6k_bn False\n549 block6k_activation False\n550 block6k_se_squeeze False\n551 block6k_se_reshape False\n552 block6k_se_reduce False\n553 block6k_se_expand False\n554 block6k_se_excite False\n555 block6k_project_conv False\n556 block6k_project_bn False\n557 block6k_drop False\n558 block6k_add False\n559 block6l_expand_conv False\n560 block6l_expand_bn False\n561 block6l_expand_activation False\n562 block6l_dwconv2 False\n563 block6l_bn False\n564 block6l_activation False\n565 block6l_se_squeeze False\n566 block6l_se_reshape False\n567 block6l_se_reduce False\n568 block6l_se_expand False\n569 block6l_se_excite False\n570 block6l_project_conv False\n571 block6l_project_bn False\n572 block6l_drop False\n573 block6l_add False\n574 block6m_expand_conv False\n575 block6m_expand_bn False\n576 block6m_expand_activation False\n577 block6m_dwconv2 False\n578 block6m_bn False\n579 block6m_activation False\n580 block6m_se_squeeze False\n581 block6m_se_reshape False\n582 block6m_se_reduce False\n583 block6m_se_expand False\n584 block6m_se_excite False\n585 block6m_project_conv False\n586 block6m_project_bn False\n587 block6m_drop False\n588 block6m_add False\n589 block6n_expand_conv False\n590 block6n_expand_bn False\n591 block6n_expand_activation False\n592 block6n_dwconv2 False\n593 block6n_bn False\n594 block6n_activation False\n595 block6n_se_squeeze False\n596 block6n_se_reshape False\n597 block6n_se_reduce False\n598 block6n_se_expand False\n599 block6n_se_excite False\n600 block6n_project_conv False\n601 block6n_project_bn False\n602 block6n_drop False\n603 block6n_add False\n604 block6o_expand_conv False\n605 block6o_expand_bn False\n606 block6o_expand_activation False\n607 block6o_dwconv2 False\n608 block6o_bn False\n609 block6o_activation False\n610 block6o_se_squeeze False\n611 block6o_se_reshape False\n612 block6o_se_reduce False\n613 block6o_se_expand False\n614 block6o_se_excite False\n615 block6o_project_conv False\n616 block6o_project_bn False\n617 block6o_drop False\n618 block6o_add False\n619 block6p_expand_conv False\n620 block6p_expand_bn False\n621 block6p_expand_activation False\n622 block6p_dwconv2 False\n623 block6p_bn False\n624 block6p_activation False\n625 block6p_se_squeeze False\n626 block6p_se_reshape False\n627 block6p_se_reduce False\n628 block6p_se_expand False\n629 block6p_se_excite False\n630 block6p_project_conv False\n631 block6p_project_bn False\n632 block6p_drop False\n633 block6p_add False\n634 block6q_expand_conv False\n635 block6q_expand_bn False\n636 block6q_expand_activation False\n637 block6q_dwconv2 False\n638 block6q_bn False\n639 block6q_activation False\n640 block6q_se_squeeze False\n641 block6q_se_reshape False\n642 block6q_se_reduce False\n643 block6q_se_expand False\n644 block6q_se_excite False\n645 block6q_project_conv False\n646 block6q_project_bn False\n647 block6q_drop False\n648 block6q_add False\n649 block6r_expand_conv False\n650 block6r_expand_bn False\n651 block6r_expand_activation False\n652 block6r_dwconv2 False\n653 block6r_bn False\n654 block6r_activation False\n655 block6r_se_squeeze False\n656 block6r_se_reshape False\n657 block6r_se_reduce False\n658 block6r_se_expand False\n659 block6r_se_excite False\n660 block6r_project_conv False\n661 block6r_project_bn False\n662 block6r_drop False\n663 block6r_add False\n664 block7a_expand_conv True\n665 block7a_expand_bn True\n666 block7a_expand_activation True\n667 block7a_dwconv2 True\n668 block7a_bn True\n669 block7a_activation True\n670 block7a_se_squeeze True\n671 block7a_se_reshape True\n672 block7a_se_reduce True\n673 block7a_se_expand True\n674 block7a_se_excite True\n675 block7a_project_conv True\n676 block7a_project_bn True\n677 block7b_expand_conv True\n678 block7b_expand_bn True\n679 block7b_expand_activation True\n680 block7b_dwconv2 True\n681 block7b_bn True\n682 block7b_activation True\n683 block7b_se_squeeze True\n684 block7b_se_reshape True\n685 block7b_se_reduce True\n686 block7b_se_expand True\n687 block7b_se_excite True\n688 block7b_project_conv True\n689 block7b_project_bn True\n690 block7b_drop True\n691 block7b_add True\n692 block7c_expand_conv True\n693 block7c_expand_bn True\n694 block7c_expand_activation True\n695 block7c_dwconv2 True\n696 block7c_bn True\n697 block7c_activation True\n698 block7c_se_squeeze True\n699 block7c_se_reshape True\n700 block7c_se_reduce True\n701 block7c_se_expand True\n702 block7c_se_excite True\n703 block7c_project_conv True\n704 block7c_project_bn True\n705 block7c_drop True\n706 block7c_add True\n707 block7d_expand_conv True\n708 block7d_expand_bn True\n709 block7d_expand_activation True\n710 block7d_dwconv2 True\n711 block7d_bn True\n712 block7d_activation True\n713 block7d_se_squeeze True\n714 block7d_se_reshape True\n715 block7d_se_reduce True\n716 block7d_se_expand True\n717 block7d_se_excite True\n718 block7d_project_conv True\n719 block7d_project_bn True\n720 block7d_drop True\n721 block7d_add True\n722 block7e_expand_conv True\n723 block7e_expand_bn True\n724 block7e_expand_activation True\n725 block7e_dwconv2 True\n726 block7e_bn True\n727 block7e_activation True\n728 block7e_se_squeeze True\n729 block7e_se_reshape True\n730 block7e_se_reduce True\n731 block7e_se_expand True\n732 block7e_se_excite True\n733 block7e_project_conv True\n734 block7e_project_bn True\n735 block7e_drop True\n736 block7e_add True\n737 top_conv True\n738 top_bn True\n739 top_activation True\n740 avg_pool True\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_4 (InputLayer)        [(None, 96, 96, 3)]       0         \n                                                                 \n preprocessing (Sequential)  (None, 96, 96, 3)         0         \n                                                                 \n efficientnetv2-m (Functiona  (None, 1280)             53150388  \n l)                                                              \n                                                                 \n dense_3 (Dense)             (None, 64)                81984     \n                                                                 \n BatchNorm0 (BatchNormalizat  (None, 64)               256       \n ion)                                                            \n                                                                 \n dense_4 (Dense)             (None, 2)                 130       \n                                                                 \n=================================================================\nTotal params: 53,232,758\nTrainable params: 18,437,710\nNon-trainable params: 34,795,048\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define optimizer, loss, and metrics\n# AdamW is an Adam optimizer which applies weight_decay to network layers,\n# i.e it's another way to apply l2 regularization to the whole network\noptimizer = tfk.optimizers.AdamW(1e-5, weight_decay=5e-4)\nloss = tfk.losses.CategoricalCrossentropy()\nmetrics = ['accuracy']\n\n# Compile the model with Categorical Cross-Entropy loss and Adam optimizer\nalldata_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n\n# Display model summary\nalldata_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:56:32.282806Z","iopub.execute_input":"2023-11-10T10:56:32.283187Z","iopub.status.idle":"2023-11-10T10:56:32.424119Z","shell.execute_reply.started":"2023-11-10T10:56:32.283159Z","shell.execute_reply":"2023-11-10T10:56:32.423227Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_4 (InputLayer)        [(None, 96, 96, 3)]       0         \n                                                                 \n preprocessing (Sequential)  (None, 96, 96, 3)         0         \n                                                                 \n efficientnetv2-m (Functiona  (None, 1280)             53150388  \n l)                                                              \n                                                                 \n dense_3 (Dense)             (None, 64)                81984     \n                                                                 \n BatchNorm0 (BatchNormalizat  (None, 64)               256       \n ion)                                                            \n                                                                 \n dense_4 (Dense)             (None, 2)                 130       \n                                                                 \n=================================================================\nTotal params: 53,232,758\nTrainable params: 18,437,710\nNon-trainable params: 34,795,048\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#train, validation, test split (80,10,10)\n\n#one-hot encoding\ny = tfk.utils.to_categorical(Y,2)\n\n# Split data into train_val and test sets\nX_train_final, X_val_final, y_train_final, y_val_final = train_test_split(X, y, random_state=seed, test_size=260, stratify=np.argmax(y,axis=1))","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:58:16.249741Z","iopub.execute_input":"2023-11-10T10:58:16.251095Z","iopub.status.idle":"2023-11-10T10:58:16.415002Z","shell.execute_reply.started":"2023-11-10T10:58:16.251052Z","shell.execute_reply":"2023-11-10T10:58:16.414124Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print(f\"X_train shape: {X_train_final.shape}, y_train shape: {y_train_final.shape}\")\nprint(f\"X_val shape: {X_val_final.shape}, y_val shape: {y_val_final.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:58:46.590960Z","iopub.execute_input":"2023-11-10T10:58:46.591351Z","iopub.status.idle":"2023-11-10T10:58:46.596716Z","shell.execute_reply.started":"2023-11-10T10:58:46.591320Z","shell.execute_reply":"2023-11-10T10:58:46.595658Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"X_train shape: (4744, 96, 96, 3), y_train shape: (4744, 2)\nX_val shape: (260, 96, 96, 3), y_val shape: (260, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"alldata_history = alldata_model.fit(\n    x = preprocess_input(X_train_final*255), # We need to apply the preprocessing thought for the MobileNetV2 network\n    y = y_train_final,\n    batch_size = 64,\n    epochs = 200,\n    validation_data = (preprocess_input(X_val_final*255), y_val_final), # We need to apply the preprocessing thought for the EfficientNetV2 network\n    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True),\n                tfk.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=20, min_lr=1e-5, mode='max')]\n).history","metadata":{"execution":{"iopub.status.busy":"2023-11-10T10:59:40.632502Z","iopub.execute_input":"2023-11-10T10:59:40.632856Z","iopub.status.idle":"2023-11-10T11:05:49.804530Z","shell.execute_reply.started":"2023-11-10T10:59:40.632829Z","shell.execute_reply":"2023-11-10T11:05:49.803442Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Epoch 1/200\n75/75 [==============================] - 50s 216ms/step - loss: 0.1961 - accuracy: 0.9281 - val_loss: 0.1937 - val_accuracy: 0.9500 - lr: 1.0000e-05\nEpoch 2/200\n75/75 [==============================] - 9s 122ms/step - loss: 0.1774 - accuracy: 0.9294 - val_loss: 0.1873 - val_accuracy: 0.9500 - lr: 1.0000e-05\nEpoch 3/200\n75/75 [==============================] - 9s 121ms/step - loss: 0.1823 - accuracy: 0.9288 - val_loss: 0.1845 - val_accuracy: 0.9385 - lr: 1.0000e-05\nEpoch 4/200\n75/75 [==============================] - 9s 121ms/step - loss: 0.1691 - accuracy: 0.9342 - val_loss: 0.1831 - val_accuracy: 0.9423 - lr: 1.0000e-05\nEpoch 5/200\n75/75 [==============================] - 9s 121ms/step - loss: 0.1672 - accuracy: 0.9349 - val_loss: 0.1788 - val_accuracy: 0.9462 - lr: 1.0000e-05\nEpoch 6/200\n75/75 [==============================] - 9s 119ms/step - loss: 0.1733 - accuracy: 0.9351 - val_loss: 0.1847 - val_accuracy: 0.9423 - lr: 1.0000e-05\nEpoch 7/200\n75/75 [==============================] - 9s 119ms/step - loss: 0.1772 - accuracy: 0.9309 - val_loss: 0.1717 - val_accuracy: 0.9423 - lr: 1.0000e-05\nEpoch 8/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1782 - accuracy: 0.9294 - val_loss: 0.1720 - val_accuracy: 0.9423 - lr: 1.0000e-05\nEpoch 9/200\n75/75 [==============================] - 9s 125ms/step - loss: 0.1712 - accuracy: 0.9328 - val_loss: 0.1782 - val_accuracy: 0.9538 - lr: 1.0000e-05\nEpoch 10/200\n75/75 [==============================] - 9s 125ms/step - loss: 0.1728 - accuracy: 0.9336 - val_loss: 0.1671 - val_accuracy: 0.9577 - lr: 1.0000e-05\nEpoch 11/200\n75/75 [==============================] - 9s 121ms/step - loss: 0.1690 - accuracy: 0.9342 - val_loss: 0.1687 - val_accuracy: 0.9500 - lr: 1.0000e-05\nEpoch 12/200\n75/75 [==============================] - 9s 121ms/step - loss: 0.1632 - accuracy: 0.9351 - val_loss: 0.1695 - val_accuracy: 0.9462 - lr: 1.0000e-05\nEpoch 13/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1598 - accuracy: 0.9384 - val_loss: 0.1675 - val_accuracy: 0.9462 - lr: 1.0000e-05\nEpoch 14/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1596 - accuracy: 0.9412 - val_loss: 0.1694 - val_accuracy: 0.9538 - lr: 1.0000e-05\nEpoch 15/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1592 - accuracy: 0.9376 - val_loss: 0.1738 - val_accuracy: 0.9577 - lr: 1.0000e-05\nEpoch 16/200\n75/75 [==============================] - 9s 125ms/step - loss: 0.1532 - accuracy: 0.9395 - val_loss: 0.1725 - val_accuracy: 0.9615 - lr: 1.0000e-05\nEpoch 17/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1618 - accuracy: 0.9342 - val_loss: 0.1745 - val_accuracy: 0.9538 - lr: 1.0000e-05\nEpoch 18/200\n75/75 [==============================] - 9s 121ms/step - loss: 0.1555 - accuracy: 0.9416 - val_loss: 0.1728 - val_accuracy: 0.9615 - lr: 1.0000e-05\nEpoch 19/200\n75/75 [==============================] - 9s 121ms/step - loss: 0.1563 - accuracy: 0.9425 - val_loss: 0.1714 - val_accuracy: 0.9423 - lr: 1.0000e-05\nEpoch 20/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1601 - accuracy: 0.9355 - val_loss: 0.1730 - val_accuracy: 0.9577 - lr: 1.0000e-05\nEpoch 21/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1535 - accuracy: 0.9391 - val_loss: 0.1766 - val_accuracy: 0.9500 - lr: 1.0000e-05\nEpoch 22/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1626 - accuracy: 0.9340 - val_loss: 0.1705 - val_accuracy: 0.9538 - lr: 1.0000e-05\nEpoch 23/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1464 - accuracy: 0.9416 - val_loss: 0.1719 - val_accuracy: 0.9538 - lr: 1.0000e-05\nEpoch 24/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1574 - accuracy: 0.9395 - val_loss: 0.1686 - val_accuracy: 0.9462 - lr: 1.0000e-05\nEpoch 25/200\n75/75 [==============================] - 9s 121ms/step - loss: 0.1548 - accuracy: 0.9368 - val_loss: 0.1699 - val_accuracy: 0.9538 - lr: 1.0000e-05\nEpoch 26/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1567 - accuracy: 0.9403 - val_loss: 0.1737 - val_accuracy: 0.9577 - lr: 1.0000e-05\nEpoch 27/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1489 - accuracy: 0.9399 - val_loss: 0.1772 - val_accuracy: 0.9538 - lr: 1.0000e-05\nEpoch 28/200\n75/75 [==============================] - 9s 119ms/step - loss: 0.1553 - accuracy: 0.9414 - val_loss: 0.1754 - val_accuracy: 0.9577 - lr: 1.0000e-05\nEpoch 29/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1499 - accuracy: 0.9382 - val_loss: 0.1795 - val_accuracy: 0.9500 - lr: 1.0000e-05\nEpoch 30/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1444 - accuracy: 0.9458 - val_loss: 0.1804 - val_accuracy: 0.9538 - lr: 1.0000e-05\nEpoch 31/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1506 - accuracy: 0.9382 - val_loss: 0.1785 - val_accuracy: 0.9577 - lr: 1.0000e-05\nEpoch 32/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1426 - accuracy: 0.9429 - val_loss: 0.1774 - val_accuracy: 0.9538 - lr: 1.0000e-05\nEpoch 33/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1348 - accuracy: 0.9481 - val_loss: 0.1811 - val_accuracy: 0.9538 - lr: 1.0000e-05\nEpoch 34/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1422 - accuracy: 0.9446 - val_loss: 0.1863 - val_accuracy: 0.9577 - lr: 1.0000e-05\nEpoch 35/200\n75/75 [==============================] - 9s 120ms/step - loss: 0.1361 - accuracy: 0.9446 - val_loss: 0.1786 - val_accuracy: 0.9577 - lr: 1.0000e-05\nEpoch 36/200\n75/75 [==============================] - 10s 127ms/step - loss: 0.1497 - accuracy: 0.9397 - val_loss: 0.1768 - val_accuracy: 0.9577 - lr: 1.0000e-05\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the best model\nalldata_model.save('EFFICIENTNET-AUG-FC-BATCHNORM-FT-ALLDATA')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-10T11:07:27.380268Z","iopub.execute_input":"2023-11-10T11:07:27.381110Z","iopub.status.idle":"2023-11-10T11:10:53.426632Z","shell.execute_reply.started":"2023-11-10T11:07:27.381069Z","shell.execute_reply":"2023-11-10T11:10:53.425518Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"!zip -r EFFICIENTNET-AUG-FC-BATCHNORM-FT-ALLDATA.zip /kaggle/working/EFFICIENTNET-AUG-FC-BATCHNORM-FT-ALLDATA","metadata":{"execution":{"iopub.status.busy":"2023-11-10T11:11:29.436683Z","iopub.execute_input":"2023-11-10T11:11:29.437857Z","iopub.status.idle":"2023-11-10T11:11:51.575820Z","shell.execute_reply.started":"2023-11-10T11:11:29.437818Z","shell.execute_reply":"2023-11-10T11:11:51.574679Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/EFFICIENTNET-AUG-FC-BATCHNORM-FT-ALLDATA/ (stored 0%)\n  adding: kaggle/working/EFFICIENTNET-AUG-FC-BATCHNORM-FT-ALLDATA/assets/ (stored 0%)\n  adding: kaggle/working/EFFICIENTNET-AUG-FC-BATCHNORM-FT-ALLDATA/keras_metadata.pb (deflated 96%)\n  adding: kaggle/working/EFFICIENTNET-AUG-FC-BATCHNORM-FT-ALLDATA/saved_model.pb (deflated 92%)\n  adding: kaggle/working/EFFICIENTNET-AUG-FC-BATCHNORM-FT-ALLDATA/fingerprint.pb (stored 0%)\n  adding: kaggle/working/EFFICIENTNET-AUG-FC-BATCHNORM-FT-ALLDATA/variables/ (stored 0%)\n  adding: kaggle/working/EFFICIENTNET-AUG-FC-BATCHNORM-FT-ALLDATA/variables/variables.index (deflated 77%)\n  adding: kaggle/working/EFFICIENTNET-AUG-FC-BATCHNORM-FT-ALLDATA/variables/variables.data-00000-of-00001 (deflated 8%)\n","output_type":"stream"}]}]}
